{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01e638ee",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-08T16:28:56.759134Z",
     "iopub.status.busy": "2026-01-08T16:28:56.758842Z",
     "iopub.status.idle": "2026-01-08T21:50:26.400768Z",
     "shell.execute_reply": "2026-01-08T21:50:26.399487Z"
    },
    "papermill": {
     "duration": 19289.647887,
     "end_time": "2026-01-08T21:50:26.402719",
     "exception": false,
     "start_time": "2026-01-08T16:28:56.754832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading datasets...\n",
      "\n",
      "[TRAIN SET]\n",
      "Preprocessing 50000 images (this happens once)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cached 50000 preprocessed images\n",
      "\n",
      "[TEST SET]\n",
      "Preprocessing 10000 images (this happens once)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cached 10000 preprocessed images\n",
      "\n",
      "Extracting Features for Analysis...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65b4556438fa425ba0dbc6d7926bcba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/46.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing Data: 100%|██████████| 50000/50000 [03:45<00:00, 221.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running k-NN Agreement & Class Balancing...\n",
      "\n",
      "Train set ready: 50000 samples (with runtime augmentation)\n",
      "Test set ready: 10000 samples (fully cached)\n",
      "\n",
      "Loading model: resnet18 (pretrained on imagenet)\n",
      "Total parameters: 11,227,812\n",
      "Trainable parameters: 11,227,812\n",
      "\n",
      "Optimizer: AdamW (lr=0.0005, weight_decay=0.05)\n",
      "Scheduler: WarmRestarts (T_0=30, T_mult=1, Step: Per-Batch)\n",
      "\n",
      "======================================================================\n",
      "Starting Training - 100 epochs\n",
      "Model: resnet18 (pretrained on imagenet)\n",
      "Optimizer: ADAMW, LR: 0.0005, Batch Size: 128\n",
      "Weight Decay: 0.05, Label Smoothing: 0.1\n",
      "Scheduler: warm_restarts\n",
      "Early Stopping: Enabled (patience=35, mode=max)\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n",
      "Keep Rate: 100.00% | Threshold: 3.0000 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | Train: 13.74% | Val: 54.14% | Best: 54.14% | LR: 0.000499:   1%|          | 1/100 [03:52<6:23:42, 232.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | Train: 13.74% | Val: 54.14% | Best: 54.14% | LR: 0.000499\n",
      "\n",
      "Epoch 2/100\n",
      "Keep Rate: 100.00% | Threshold: 3.0000 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 | Train: 21.26% | Val: 60.68% | Best: 60.68% | LR: 0.000495:   2%|▏         | 2/100 [07:33<6:09:06, 225.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 | Train: 21.26% | Val: 60.68% | Best: 60.68% | LR: 0.000495\n",
      "\n",
      "Epoch 3/100\n",
      "Keep Rate: 100.00% | Threshold: 3.0000 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 | Train: 22.11% | Val: 63.62% | Best: 63.62% | LR: 0.000488:   3%|▎         | 3/100 [11:16<6:02:29, 224.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 | Train: 22.11% | Val: 63.62% | Best: 63.62% | LR: 0.000488\n",
      "\n",
      "Epoch 4/100\n",
      "Keep Rate: 100.00% | Threshold: 3.0000 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 | Train: 24.40% | Val: 64.83% | Best: 64.83% | LR: 0.000478:   4%|▍         | 4/100 [14:56<5:56:34, 222.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 | Train: 24.40% | Val: 64.83% | Best: 64.83% | LR: 0.000478\n",
      "\n",
      "Epoch 5/100\n",
      "Keep Rate: 100.00% | Threshold: 3.0000 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 | Train: 24.04% | Val: 66.52% | Best: 66.52% | LR: 0.000467:   5%|▌         | 5/100 [18:35<5:50:22, 221.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 | Train: 24.04% | Val: 66.52% | Best: 66.52% | LR: 0.000467\n",
      "\n",
      "Epoch 6/100\n",
      "Keep Rate: 100.00% | Threshold: 3.0000 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 | Train: 26.58% | Val: 67.38% | Best: 67.38% | LR: 0.000452:   6%|▌         | 6/100 [22:14<5:45:19, 220.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 | Train: 26.58% | Val: 67.38% | Best: 67.38% | LR: 0.000452\n",
      "\n",
      "Epoch 7/100\n",
      "Keep Rate: 100.00% | Threshold: 3.0000 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 | Train: 28.07% | Val: 66.78% | Best: 67.38% | LR: 0.000436:   7%|▋         | 7/100 [25:55<5:42:20, 220.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 | Train: 28.07% | Val: 66.78% | Best: 67.38% | LR: 0.000436\n",
      "\n",
      "Epoch 8/100\n",
      "Keep Rate: 100.00% | Threshold: 3.0000 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 | Train: 24.41% | Val: 68.69% | Best: 68.69% | LR: 0.000417:   8%|▊         | 8/100 [29:39<5:39:50, 221.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 | Train: 24.41% | Val: 68.69% | Best: 68.69% | LR: 0.000417\n",
      "\n",
      "Epoch 9/100\n",
      "Keep Rate: 100.00% | Threshold: 3.0000 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 | Train: 27.97% | Val: 69.11% | Best: 69.11% | LR: 0.000397:   9%|▉         | 9/100 [33:19<5:35:21, 221.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 | Train: 27.97% | Val: 69.11% | Best: 69.11% | LR: 0.000397\n",
      "\n",
      "Epoch 10/100\n",
      "Keep Rate: 100.00% | Threshold: 3.0000 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 | Train: 26.79% | Val: 68.00% | Best: 69.11% | LR: 0.000375:  10%|█         | 10/100 [36:58<5:30:53, 220.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 | Train: 26.79% | Val: 68.00% | Best: 69.11% | LR: 0.000375\n",
      "\n",
      "Epoch 11/100\n",
      "Keep Rate: 74.83% | Threshold: 2.9850 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 | Train: 37.60% | Val: 69.42% | Best: 69.42% | LR: 0.000352:  11%|█         | 11/100 [40:55<5:34:34, 225.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 | Train: 37.60% | Val: 69.42% | Best: 69.42% | LR: 0.000352\n",
      "\n",
      "Epoch 12/100\n",
      "Keep Rate: 74.53% | Threshold: 2.9701 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 | Train: 39.35% | Val: 69.83% | Best: 69.83% | LR: 0.000328:  12%|█▏        | 12/100 [44:34<5:28:06, 223.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 | Train: 39.35% | Val: 69.83% | Best: 69.83% | LR: 0.000328\n",
      "\n",
      "Epoch 13/100\n",
      "Keep Rate: 74.73% | Threshold: 2.9552 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 | Train: 34.99% | Val: 69.89% | Best: 69.89% | LR: 0.000302:  13%|█▎        | 13/100 [48:11<5:21:08, 221.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 | Train: 34.99% | Val: 69.89% | Best: 69.89% | LR: 0.000302\n",
      "\n",
      "Epoch 14/100\n",
      "Keep Rate: 74.76% | Threshold: 2.9404 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 | Train: 35.28% | Val: 70.22% | Best: 70.22% | LR: 0.000277:  14%|█▍        | 14/100 [51:48<5:15:40, 220.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 | Train: 35.28% | Val: 70.22% | Best: 70.22% | LR: 0.000277\n",
      "\n",
      "Epoch 15/100\n",
      "Keep Rate: 74.87% | Threshold: 2.9257 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100 | Train: 36.83% | Val: 70.67% | Best: 70.67% | LR: 0.000251:  15%|█▌        | 15/100 [55:23<5:09:49, 218.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100 | Train: 36.83% | Val: 70.67% | Best: 70.67% | LR: 0.000251\n",
      "\n",
      "Epoch 16/100\n",
      "Keep Rate: 74.90% | Threshold: 2.9111 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100 | Train: 37.53% | Val: 70.34% | Best: 70.67% | LR: 0.000224:  16%|█▌        | 16/100 [58:58<5:04:22, 217.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100 | Train: 37.53% | Val: 70.34% | Best: 70.67% | LR: 0.000224\n",
      "\n",
      "Epoch 17/100\n",
      "Keep Rate: 75.07% | Threshold: 2.8966 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100 | Train: 35.58% | Val: 70.29% | Best: 70.67% | LR: 0.000199:  17%|█▋        | 17/100 [1:02:32<4:59:25, 216.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100 | Train: 35.58% | Val: 70.29% | Best: 70.67% | LR: 0.000199\n",
      "\n",
      "Epoch 18/100\n",
      "Keep Rate: 75.25% | Threshold: 2.8821 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100 | Train: 36.84% | Val: 70.60% | Best: 70.67% | LR: 0.000173:  18%|█▊        | 18/100 [1:06:07<4:55:20, 216.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100 | Train: 36.84% | Val: 70.60% | Best: 70.67% | LR: 0.000173\n",
      "\n",
      "Epoch 19/100\n",
      "Keep Rate: 75.41% | Threshold: 2.8677 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100 | Train: 37.70% | Val: 70.77% | Best: 70.77% | LR: 0.000149:  19%|█▉        | 19/100 [1:09:42<4:51:15, 215.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100 | Train: 37.70% | Val: 70.77% | Best: 70.77% | LR: 0.000149\n",
      "\n",
      "Epoch 20/100\n",
      "Keep Rate: 75.17% | Threshold: 2.8533 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100 | Train: 38.01% | Val: 70.76% | Best: 70.77% | LR: 0.000126:  20%|██        | 20/100 [1:13:17<4:47:14, 215.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100 | Train: 38.01% | Val: 70.76% | Best: 70.77% | LR: 0.000126\n",
      "\n",
      "Epoch 21/100\n",
      "Keep Rate: 75.42% | Threshold: 2.8391 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100 | Train: 40.85% | Val: 70.96% | Best: 70.96% | LR: 0.000104:  21%|██        | 21/100 [1:16:52<4:43:44, 215.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100 | Train: 40.85% | Val: 70.96% | Best: 70.96% | LR: 0.000104\n",
      "\n",
      "Epoch 22/100\n",
      "Keep Rate: 75.34% | Threshold: 2.8249 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100 | Train: 40.28% | Val: 70.86% | Best: 70.96% | LR: 0.000084:  22%|██▏       | 22/100 [1:20:25<4:39:03, 214.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100 | Train: 40.28% | Val: 70.86% | Best: 70.96% | LR: 0.000084\n",
      "\n",
      "Epoch 23/100\n",
      "Keep Rate: 75.28% | Threshold: 2.8107 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100 | Train: 38.92% | Val: 70.88% | Best: 70.96% | LR: 0.000065:  23%|██▎       | 23/100 [1:23:58<4:34:57, 214.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100 | Train: 38.92% | Val: 70.88% | Best: 70.96% | LR: 0.000065\n",
      "\n",
      "Epoch 24/100\n",
      "Keep Rate: 75.41% | Threshold: 2.7967 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100 | Train: 39.95% | Val: 71.48% | Best: 71.48% | LR: 0.000049:  24%|██▍       | 24/100 [1:27:33<4:31:31, 214.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100 | Train: 39.95% | Val: 71.48% | Best: 71.48% | LR: 0.000049\n",
      "\n",
      "Epoch 25/100\n",
      "Keep Rate: 75.39% | Threshold: 2.7827 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100 | Train: 37.97% | Val: 71.61% | Best: 71.61% | LR: 0.000034:  25%|██▌       | 25/100 [1:31:07<4:27:48, 214.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100 | Train: 37.97% | Val: 71.61% | Best: 71.61% | LR: 0.000034\n",
      "\n",
      "Epoch 26/100\n",
      "Keep Rate: 75.42% | Threshold: 2.7688 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100 | Train: 40.37% | Val: 71.41% | Best: 71.61% | LR: 0.000023:  26%|██▌       | 26/100 [1:34:42<4:24:22, 214.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100 | Train: 40.37% | Val: 71.41% | Best: 71.61% | LR: 0.000023\n",
      "\n",
      "Epoch 27/100\n",
      "Keep Rate: 75.49% | Threshold: 2.7549 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100 | Train: 40.89% | Val: 71.58% | Best: 71.61% | LR: 0.000013:  27%|██▋       | 27/100 [1:38:20<4:22:20, 215.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100 | Train: 40.89% | Val: 71.58% | Best: 71.61% | LR: 0.000013\n",
      "\n",
      "Epoch 28/100\n",
      "Keep Rate: 75.20% | Threshold: 2.7412 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100 | Train: 39.27% | Val: 71.36% | Best: 71.61% | LR: 0.000006:  28%|██▊       | 28/100 [1:41:54<4:17:54, 214.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100 | Train: 39.27% | Val: 71.36% | Best: 71.61% | LR: 0.000006\n",
      "\n",
      "Epoch 29/100\n",
      "Keep Rate: 75.14% | Threshold: 2.7275 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100 | Train: 39.79% | Val: 71.38% | Best: 71.61% | LR: 0.000002:  29%|██▉       | 29/100 [1:45:27<4:13:44, 214.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100 | Train: 39.79% | Val: 71.38% | Best: 71.61% | LR: 0.000002\n",
      "\n",
      "Epoch 30/100\n",
      "Keep Rate: 75.15% | Threshold: 2.7138 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100 | Train: 39.49% | Val: 71.08% | Best: 71.61% | LR: 0.000001:  30%|███       | 30/100 [1:49:01<4:10:04, 214.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100 | Train: 39.49% | Val: 71.08% | Best: 71.61% | LR: 0.000001\n",
      "\n",
      "Epoch 31/100\n",
      "Keep Rate: 73.48% | Threshold: 2.7003 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100 | Train: 39.90% | Val: 69.16% | Best: 71.61% | LR: 0.000499:  31%|███       | 31/100 [1:52:35<4:06:21, 214.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100 | Train: 39.90% | Val: 69.16% | Best: 71.61% | LR: 0.000499\n",
      "\n",
      "Epoch 32/100\n",
      "Keep Rate: 73.21% | Threshold: 2.6868 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100 | Train: 39.83% | Val: 69.12% | Best: 71.61% | LR: 0.000495:  32%|███▏      | 32/100 [1:56:09<4:02:50, 214.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100 | Train: 39.83% | Val: 69.12% | Best: 71.61% | LR: 0.000495\n",
      "\n",
      "Epoch 33/100\n",
      "Keep Rate: 73.16% | Threshold: 2.6733 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100 | Train: 37.96% | Val: 69.69% | Best: 71.61% | LR: 0.000488:  33%|███▎      | 33/100 [1:59:42<3:58:53, 213.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100 | Train: 37.96% | Val: 69.69% | Best: 71.61% | LR: 0.000488\n",
      "\n",
      "Epoch 34/100\n",
      "Keep Rate: 73.11% | Threshold: 2.6600 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100 | Train: 37.68% | Val: 69.33% | Best: 71.61% | LR: 0.000478:  34%|███▍      | 34/100 [2:03:16<3:55:07, 213.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100 | Train: 37.68% | Val: 69.33% | Best: 71.61% | LR: 0.000478\n",
      "\n",
      "Epoch 35/100\n",
      "Keep Rate: 73.10% | Threshold: 2.6467 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100 | Train: 39.10% | Val: 68.84% | Best: 71.61% | LR: 0.000467:  35%|███▌      | 35/100 [2:06:58<3:54:16, 216.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100 | Train: 39.10% | Val: 68.84% | Best: 71.61% | LR: 0.000467\n",
      "\n",
      "Epoch 36/100\n",
      "Keep Rate: 73.05% | Threshold: 2.6334 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100 | Train: 52.97% | Val: 70.05% | Best: 71.61% | LR: 0.000452:  36%|███▌      | 36/100 [2:11:13<4:02:59, 227.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100 | Train: 52.97% | Val: 70.05% | Best: 71.61% | LR: 0.000452\n",
      "\n",
      "Epoch 37/100\n",
      "Keep Rate: 72.93% | Threshold: 2.6203 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100 | Train: 54.55% | Val: 70.34% | Best: 71.61% | LR: 0.000436:  37%|███▋      | 37/100 [2:15:00<3:58:56, 227.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100 | Train: 54.55% | Val: 70.34% | Best: 71.61% | LR: 0.000436\n",
      "\n",
      "Epoch 38/100\n",
      "Keep Rate: 73.08% | Threshold: 2.6072 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100 | Train: 54.45% | Val: 70.60% | Best: 71.61% | LR: 0.000417:  38%|███▊      | 38/100 [2:18:49<3:55:36, 228.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100 | Train: 54.45% | Val: 70.60% | Best: 71.61% | LR: 0.000417\n",
      "\n",
      "Epoch 39/100\n",
      "Keep Rate: 72.99% | Threshold: 2.5941 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100 | Train: 55.19% | Val: 69.84% | Best: 71.61% | LR: 0.000397:  39%|███▉      | 39/100 [2:22:37<3:51:56, 228.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100 | Train: 55.19% | Val: 69.84% | Best: 71.61% | LR: 0.000397\n",
      "\n",
      "Epoch 40/100\n",
      "Keep Rate: 73.06% | Threshold: 2.5812 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100 | Train: 57.71% | Val: 70.73% | Best: 71.61% | LR: 0.000375:  40%|████      | 40/100 [2:26:23<3:47:29, 227.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100 | Train: 57.71% | Val: 70.73% | Best: 71.61% | LR: 0.000375\n",
      "\n",
      "Epoch 41/100\n",
      "Keep Rate: 73.08% | Threshold: 2.5682 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100 | Train: 55.72% | Val: 71.12% | Best: 71.61% | LR: 0.000352:  41%|████      | 41/100 [2:30:07<3:42:46, 226.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100 | Train: 55.72% | Val: 71.12% | Best: 71.61% | LR: 0.000352\n",
      "\n",
      "Epoch 42/100\n",
      "Keep Rate: 73.35% | Threshold: 2.5554 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100 | Train: 55.85% | Val: 70.12% | Best: 71.61% | LR: 0.000328:  42%|████▏     | 42/100 [2:33:55<3:39:23, 226.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100 | Train: 55.85% | Val: 70.12% | Best: 71.61% | LR: 0.000328\n",
      "\n",
      "Epoch 43/100\n",
      "Keep Rate: 73.43% | Threshold: 2.5426 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/100 | Train: 53.28% | Val: 70.74% | Best: 71.61% | LR: 0.000302:  43%|████▎     | 43/100 [2:37:41<3:35:19, 226.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100 | Train: 53.28% | Val: 70.74% | Best: 71.61% | LR: 0.000302\n",
      "\n",
      "Epoch 44/100\n",
      "Keep Rate: 73.37% | Threshold: 2.5299 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/100 | Train: 58.69% | Val: 70.82% | Best: 71.61% | LR: 0.000277:  44%|████▍     | 44/100 [2:41:26<3:30:59, 226.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100 | Train: 58.69% | Val: 70.82% | Best: 71.61% | LR: 0.000277\n",
      "\n",
      "Epoch 45/100\n",
      "Keep Rate: 73.61% | Threshold: 2.5173 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/100 | Train: 57.85% | Val: 71.28% | Best: 71.61% | LR: 0.000251:  45%|████▌     | 45/100 [2:45:12<3:27:11, 226.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100 | Train: 57.85% | Val: 71.28% | Best: 71.61% | LR: 0.000251\n",
      "\n",
      "Epoch 46/100\n",
      "Keep Rate: 73.67% | Threshold: 2.5047 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/100 | Train: 56.50% | Val: 71.53% | Best: 71.61% | LR: 0.000224:  46%|████▌     | 46/100 [2:49:01<3:24:20, 227.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100 | Train: 56.50% | Val: 71.53% | Best: 71.61% | LR: 0.000224\n",
      "\n",
      "Epoch 47/100\n",
      "Keep Rate: 73.89% | Threshold: 2.4922 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/100 | Train: 58.68% | Val: 71.50% | Best: 71.61% | LR: 0.000199:  47%|████▋     | 47/100 [2:53:05<3:25:00, 232.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100 | Train: 58.68% | Val: 71.50% | Best: 71.61% | LR: 0.000199\n",
      "\n",
      "Epoch 48/100\n",
      "Keep Rate: 73.86% | Threshold: 2.4797 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/100 | Train: 59.49% | Val: 71.34% | Best: 71.61% | LR: 0.000173:  48%|████▊     | 48/100 [2:57:33<3:30:21, 242.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100 | Train: 59.49% | Val: 71.34% | Best: 71.61% | LR: 0.000173\n",
      "\n",
      "Epoch 49/100\n",
      "Keep Rate: 73.91% | Threshold: 2.4673 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/100 | Train: 57.84% | Val: 71.88% | Best: 71.88% | LR: 0.000149:  49%|████▉     | 49/100 [3:01:31<3:25:17, 241.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100 | Train: 57.84% | Val: 71.88% | Best: 71.88% | LR: 0.000149\n",
      "\n",
      "Epoch 50/100\n",
      "Keep Rate: 74.00% | Threshold: 2.4550 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/100 | Train: 59.73% | Val: 71.58% | Best: 71.88% | LR: 0.000126:  50%|█████     | 50/100 [3:05:14<3:16:37, 235.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100 | Train: 59.73% | Val: 71.58% | Best: 71.88% | LR: 0.000126\n",
      "\n",
      "Epoch 51/100\n",
      "Keep Rate: 73.93% | Threshold: 2.4427 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100 | Train: 59.10% | Val: 71.67% | Best: 71.88% | LR: 0.000104:  51%|█████     | 51/100 [3:09:01<3:10:21, 233.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100 | Train: 59.10% | Val: 71.67% | Best: 71.88% | LR: 0.000104\n",
      "\n",
      "Epoch 52/100\n",
      "Keep Rate: 74.15% | Threshold: 2.4305 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/100 | Train: 57.47% | Val: 71.28% | Best: 71.88% | LR: 0.000084:  52%|█████▏    | 52/100 [3:13:08<3:09:45, 237.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100 | Train: 57.47% | Val: 71.28% | Best: 71.88% | LR: 0.000084\n",
      "\n",
      "Epoch 53/100\n",
      "Keep Rate: 74.23% | Threshold: 2.4183 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/100 | Train: 60.00% | Val: 71.53% | Best: 71.88% | LR: 0.000065:  53%|█████▎    | 53/100 [3:16:54<3:03:19, 234.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100 | Train: 60.00% | Val: 71.53% | Best: 71.88% | LR: 0.000065\n",
      "\n",
      "Epoch 54/100\n",
      "Keep Rate: 74.15% | Threshold: 2.4062 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/100 | Train: 58.47% | Val: 71.49% | Best: 71.88% | LR: 0.000049:  54%|█████▍    | 54/100 [3:20:42<2:57:53, 232.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100 | Train: 58.47% | Val: 71.49% | Best: 71.88% | LR: 0.000049\n",
      "\n",
      "Epoch 55/100\n",
      "Keep Rate: 74.05% | Threshold: 2.3942 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/100 | Train: 60.17% | Val: 71.49% | Best: 71.88% | LR: 0.000034:  55%|█████▌    | 55/100 [3:24:30<2:53:09, 230.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100 | Train: 60.17% | Val: 71.49% | Best: 71.88% | LR: 0.000034\n",
      "\n",
      "Epoch 56/100\n",
      "Keep Rate: 74.16% | Threshold: 2.3822 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/100 | Train: 60.41% | Val: 71.47% | Best: 71.88% | LR: 0.000023:  56%|█████▌    | 56/100 [3:28:15<2:48:04, 229.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100 | Train: 60.41% | Val: 71.47% | Best: 71.88% | LR: 0.000023\n",
      "\n",
      "Epoch 57/100\n",
      "Keep Rate: 74.10% | Threshold: 2.3703 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/100 | Train: 57.97% | Val: 71.48% | Best: 71.88% | LR: 0.000013:  57%|█████▋    | 57/100 [3:32:11<2:45:37, 231.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100 | Train: 57.97% | Val: 71.48% | Best: 71.88% | LR: 0.000013\n",
      "\n",
      "Epoch 58/100\n",
      "Keep Rate: 73.99% | Threshold: 2.3585 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/100 | Train: 60.36% | Val: 71.84% | Best: 71.88% | LR: 0.000006:  58%|█████▊    | 58/100 [3:35:54<2:40:12, 228.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100 | Train: 60.36% | Val: 71.84% | Best: 71.88% | LR: 0.000006\n",
      "\n",
      "Epoch 59/100\n",
      "Keep Rate: 74.05% | Threshold: 2.3467 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/100 | Train: 57.83% | Val: 71.74% | Best: 71.88% | LR: 0.000002:  59%|█████▉    | 59/100 [3:39:35<2:34:46, 226.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100 | Train: 57.83% | Val: 71.74% | Best: 71.88% | LR: 0.000002\n",
      "\n",
      "Epoch 60/100\n",
      "Keep Rate: 73.95% | Threshold: 2.3349 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/100 | Train: 61.53% | Val: 71.62% | Best: 71.88% | LR: 0.000001:  60%|██████    | 60/100 [3:43:20<2:30:41, 226.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100 | Train: 61.53% | Val: 71.62% | Best: 71.88% | LR: 0.000001\n",
      "\n",
      "Epoch 61/100\n",
      "Keep Rate: 72.48% | Threshold: 2.3233 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100 | Train: 58.07% | Val: 69.42% | Best: 71.88% | LR: 0.000499:  61%|██████    | 61/100 [3:47:04<2:26:27, 225.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100 | Train: 58.07% | Val: 69.42% | Best: 71.88% | LR: 0.000499\n",
      "\n",
      "Epoch 62/100\n",
      "Keep Rate: 72.03% | Threshold: 2.3116 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/100 | Train: 58.91% | Val: 69.50% | Best: 71.88% | LR: 0.000495:  62%|██████▏   | 62/100 [3:50:55<2:23:47, 227.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100 | Train: 58.91% | Val: 69.50% | Best: 71.88% | LR: 0.000495\n",
      "\n",
      "Epoch 63/100\n",
      "Keep Rate: 72.22% | Threshold: 2.3001 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/100 | Train: 57.16% | Val: 69.56% | Best: 71.88% | LR: 0.000488:  63%|██████▎   | 63/100 [3:54:48<2:21:03, 228.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100 | Train: 57.16% | Val: 69.56% | Best: 71.88% | LR: 0.000488\n",
      "\n",
      "Epoch 64/100\n",
      "Keep Rate: 71.98% | Threshold: 2.2886 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/100 | Train: 58.46% | Val: 70.25% | Best: 71.88% | LR: 0.000478:  64%|██████▍   | 64/100 [3:58:39<2:17:47, 229.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100 | Train: 58.46% | Val: 70.25% | Best: 71.88% | LR: 0.000478\n",
      "\n",
      "Epoch 65/100\n",
      "Keep Rate: 72.03% | Threshold: 2.2771 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/100 | Train: 60.48% | Val: 71.15% | Best: 71.88% | LR: 0.000467:  65%|██████▌   | 65/100 [4:02:30<2:14:09, 229.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100 | Train: 60.48% | Val: 71.15% | Best: 71.88% | LR: 0.000467\n",
      "\n",
      "Epoch 66/100\n",
      "Keep Rate: 71.96% | Threshold: 2.2658 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/100 | Train: 60.77% | Val: 69.74% | Best: 71.88% | LR: 0.000452:  66%|██████▌   | 66/100 [4:06:22<2:10:36, 230.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100 | Train: 60.77% | Val: 69.74% | Best: 71.88% | LR: 0.000452\n",
      "\n",
      "Epoch 67/100\n",
      "Keep Rate: 72.04% | Threshold: 2.2544 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/100 | Train: 60.54% | Val: 70.13% | Best: 71.88% | LR: 0.000436:  67%|██████▋   | 67/100 [4:10:13<2:06:56, 230.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100 | Train: 60.54% | Val: 70.13% | Best: 71.88% | LR: 0.000436\n",
      "\n",
      "Epoch 68/100\n",
      "Keep Rate: 72.51% | Threshold: 2.2432 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/100 | Train: 58.81% | Val: 69.38% | Best: 71.88% | LR: 0.000417:  68%|██████▊   | 68/100 [4:13:59<2:02:16, 229.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100 | Train: 58.81% | Val: 69.38% | Best: 71.88% | LR: 0.000417\n",
      "\n",
      "Epoch 69/100\n",
      "Keep Rate: 72.29% | Threshold: 2.2319 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/100 | Train: 60.61% | Val: 69.97% | Best: 71.88% | LR: 0.000397:  69%|██████▉   | 69/100 [4:17:59<2:00:02, 232.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100 | Train: 60.61% | Val: 69.97% | Best: 71.88% | LR: 0.000397\n",
      "\n",
      "Epoch 70/100\n",
      "Keep Rate: 72.32% | Threshold: 2.2208 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/100 | Train: 58.79% | Val: 69.57% | Best: 71.88% | LR: 0.000375:  70%|███████   | 70/100 [4:21:58<1:57:12, 234.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100 | Train: 58.79% | Val: 69.57% | Best: 71.88% | LR: 0.000375\n",
      "\n",
      "Epoch 71/100\n",
      "Keep Rate: 72.35% | Threshold: 2.2097 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/100 | Train: 58.95% | Val: 70.28% | Best: 71.88% | LR: 0.000352:  71%|███████   | 71/100 [4:25:47<1:52:30, 232.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100 | Train: 58.95% | Val: 70.28% | Best: 71.88% | LR: 0.000352\n",
      "\n",
      "Epoch 72/100\n",
      "Keep Rate: 72.67% | Threshold: 2.1986 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/100 | Train: 60.00% | Val: 69.74% | Best: 71.88% | LR: 0.000328:  72%|███████▏  | 72/100 [4:29:37<1:48:14, 231.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100 | Train: 60.00% | Val: 69.74% | Best: 71.88% | LR: 0.000328\n",
      "\n",
      "Epoch 73/100\n",
      "Keep Rate: 72.76% | Threshold: 2.1876 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/100 | Train: 57.35% | Val: 69.73% | Best: 71.88% | LR: 0.000302:  73%|███████▎  | 73/100 [4:33:29<1:44:22, 231.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100 | Train: 57.35% | Val: 69.73% | Best: 71.88% | LR: 0.000302\n",
      "\n",
      "Epoch 74/100\n",
      "Keep Rate: 73.01% | Threshold: 2.1767 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/100 | Train: 63.27% | Val: 70.59% | Best: 71.88% | LR: 0.000277:  74%|███████▍  | 74/100 [4:37:17<1:40:05, 231.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100 | Train: 63.27% | Val: 70.59% | Best: 71.88% | LR: 0.000277\n",
      "\n",
      "Epoch 75/100\n",
      "Keep Rate: 72.85% | Threshold: 2.1658 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/100 | Train: 61.43% | Val: 70.50% | Best: 71.88% | LR: 0.000251:  75%|███████▌  | 75/100 [4:41:05<1:35:48, 229.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100 | Train: 61.43% | Val: 70.50% | Best: 71.88% | LR: 0.000251\n",
      "\n",
      "Epoch 76/100\n",
      "Keep Rate: 73.03% | Threshold: 2.1550 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/100 | Train: 62.08% | Val: 70.09% | Best: 71.88% | LR: 0.000224:  76%|███████▌  | 76/100 [4:44:54<1:31:54, 229.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100 | Train: 62.08% | Val: 70.09% | Best: 71.88% | LR: 0.000224\n",
      "\n",
      "Epoch 77/100\n",
      "Keep Rate: 73.24% | Threshold: 2.1442 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/100 | Train: 62.78% | Val: 70.54% | Best: 71.88% | LR: 0.000199:  77%|███████▋  | 77/100 [4:48:40<1:27:39, 228.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100 | Train: 62.78% | Val: 70.54% | Best: 71.88% | LR: 0.000199\n",
      "\n",
      "Epoch 78/100\n",
      "Keep Rate: 73.31% | Threshold: 2.1335 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/100 | Train: 63.28% | Val: 70.47% | Best: 71.88% | LR: 0.000173:  78%|███████▊  | 78/100 [4:52:29<1:23:52, 228.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100 | Train: 63.28% | Val: 70.47% | Best: 71.88% | LR: 0.000173\n",
      "\n",
      "Epoch 79/100\n",
      "Keep Rate: 73.39% | Threshold: 2.1228 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/100 | Train: 62.78% | Val: 70.77% | Best: 71.88% | LR: 0.000149:  79%|███████▉  | 79/100 [4:56:17<1:19:57, 228.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100 | Train: 62.78% | Val: 70.77% | Best: 71.88% | LR: 0.000149\n",
      "\n",
      "Epoch 80/100\n",
      "Keep Rate: 73.39% | Threshold: 2.1122 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/100 | Train: 62.94% | Val: 70.84% | Best: 71.88% | LR: 0.000126:  80%|████████  | 80/100 [5:00:04<1:16:00, 228.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100 | Train: 62.94% | Val: 70.84% | Best: 71.88% | LR: 0.000126\n",
      "\n",
      "Epoch 81/100\n",
      "Keep Rate: 73.55% | Threshold: 2.1016 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/100 | Train: 65.35% | Val: 70.49% | Best: 71.88% | LR: 0.000104:  81%|████████  | 81/100 [5:03:55<1:12:30, 228.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100 | Train: 65.35% | Val: 70.49% | Best: 71.88% | LR: 0.000104\n",
      "\n",
      "Epoch 82/100\n",
      "Keep Rate: 73.69% | Threshold: 2.0911 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/100 | Train: 62.80% | Val: 70.52% | Best: 71.88% | LR: 0.000084:  82%|████████▏ | 82/100 [5:07:45<1:08:47, 229.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100 | Train: 62.80% | Val: 70.52% | Best: 71.88% | LR: 0.000084\n",
      "\n",
      "Epoch 83/100\n",
      "Keep Rate: 73.58% | Threshold: 2.0807 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/100 | Train: 63.66% | Val: 70.71% | Best: 71.88% | LR: 0.000065:  83%|████████▎ | 83/100 [5:11:34<1:04:55, 229.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100 | Train: 63.66% | Val: 70.71% | Best: 71.88% | LR: 0.000065\n",
      "\n",
      "Epoch 84/100\n",
      "Keep Rate: 73.66% | Threshold: 2.0703 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/100 | Train: 64.89% | Val: 70.66% | Best: 71.88% | LR: 0.000049:  83%|████████▎ | 83/100 [5:15:28<1:04:36, 228.06s/it]\n",
      "/tmp/ipykernel_24/4087130994.py:611: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('./best_model.pth')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100 | Train: 64.89% | Val: 70.66% | Best: 71.88% | LR: 0.000049\n",
      "\n",
      "============================================================\n",
      "Early stopping triggered at epoch 84\n",
      "Best Val Accuracy: 71.88% at epoch 49\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Training Complete!\n",
      "Best Val Accuracy: 71.88% at epoch 49\n",
      "Loading best model for inference...\n",
      "============================================================\n",
      "\n",
      "Best model loaded (Epoch 49, Val Acc: 71.88%)\n",
      "\n",
      "Generating predictions...\n",
      "\n",
      "============================================================\n",
      "Submission saved to: ./submission.csv\n",
      "Best model saved to: ./best_model.pth\n",
      "Best Val Accuracy: 71.88% (Epoch 49)\n",
      "Training stopped early (patience reached)\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import timm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from typing import Optional, Callable\n",
    "\n",
    "from torch import nn, Tensor, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.backends import cudnn\n",
    "from torch import GradScaler\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.datasets import CIFAR100\n",
    "from torchvision.transforms import v2\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# ============ Configuration ============\n",
    "config = {\n",
    "    \"dataset\": \"cifar100_noisy\",\n",
    "    \"model\": \"resnet18\",\n",
    "    \"pretrained\": \"imagenet\",\n",
    "    \"epochs\": 100,\n",
    "    \"batch_size\": 128,\n",
    "    \"lr\": 0.0005,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 0.05,\n",
    "    \"nesterov\": True,\n",
    "    \"label_smoothing\": 0.1,\n",
    "    \"optimizer\": \"adamw\",\n",
    "    \"scheduler\": \"warm_restarts\",     \n",
    "    \"warm_restarts_T0\": 30,              \n",
    "    \"warm_restarts_mult\": 1,             \n",
    "    \"cosine_eta_min\": 1e-6,\n",
    "    \"scheduler_step_per_batch\": True,\n",
    "    \"early_stop_patience\": 35,\n",
    "    \"early_stop_mode\": \"max\",\n",
    "    \"early_stop_min_delta\": 0.05,\n",
    "    \"device\": \"cuda\",\n",
    "    \"mixed_precision\": True,\n",
    "    \"wandb_project\": \"cifar100-noisy-competition\",\n",
    "    \"upscale_size\": 224,  \n",
    "    \"aug_alpha\": 0.5,          \n",
    "    \"cutmix_prob\": 1.0,        \n",
    "    \"switch_epoch\": 35,        \n",
    "    \"warmup_epochs\": 10,\n",
    "    \"loss_threshold\": 3.0,\n",
    "    \"dynamic_threshold_decay\": 0.995,\n",
    "    \"soft_alpha\": 0.4\n",
    "}\n",
    "\n",
    "device = torch.device(config[\"device\"])\n",
    "print(f\"Using device: {device}\")\n",
    "cudnn.benchmark = True\n",
    "pin_memory = True\n",
    "enable_half = config[\"mixed_precision\"]  # Disable for CPU, it is slower!\n",
    "scaler = GradScaler(device, enabled=enable_half)\n",
    "\n",
    "def get_refinement_metadata(dataset, device):\n",
    "    print(\"\\nExtracting Features for Analysis...\")\n",
    "    embed_model = timm.create_model('resnet18', pretrained=True, num_classes=0).to(device)\n",
    "    embed_model.eval()\n",
    "    \n",
    "    analysis_transform = v2.Compose([\n",
    "        v2.ToImage(), v2.Resize(224), v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    features, labels = [], np.array(dataset.targets)\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(len(dataset)), desc=\"Analyzing Data\"):\n",
    "            img, _ = dataset[i]\n",
    "            img_t = analysis_transform(img).unsqueeze(0).to(device)\n",
    "            features.append(embed_model(img_t).cpu().numpy())\n",
    "    \n",
    "    features = np.concatenate(features, axis=0)\n",
    "    \n",
    "    print(\"Running k-NN Agreement & Class Balancing...\")\n",
    "    K = 10\n",
    "    knn = NearestNeighbors(n_neighbors=K+1, metric='cosine').fit(features)\n",
    "    _, indices = knn.kneighbors(features)\n",
    "    \n",
    "    refurbished_labels = []\n",
    "    agreement_scores = []\n",
    "    for i in range(len(features)):\n",
    "        neighbor_labels = labels[indices[i, 1:]]\n",
    "        counts = np.bincount(neighbor_labels, minlength=100)\n",
    "        refurbished_labels.append(np.argmax(counts))\n",
    "        agreement_scores.append(counts[labels[i]] / K)\n",
    "    \n",
    "    agreement_scores = np.array(agreement_scores)\n",
    "    refurbished_labels = np.array(refurbished_labels)\n",
    "\n",
    "    stable_mask = agreement_scores >= 0.9\n",
    "    counts_per_class = np.bincount(labels[stable_mask], minlength=100)\n",
    "    rare_classes = np.where(counts_per_class < 20)[0] # Target classes below 20 samples\n",
    "    \n",
    "    for c in rare_classes:\n",
    "        # Bolster rare classes using medium agreement samples (above 75%)\n",
    "        potential_candidates = np.where((agreement_scores >= 0.75) & (refurbished_labels == c))[0]\n",
    "        agreement_scores[potential_candidates] = 0.95 # Promote to \"Stable\" status\n",
    "            \n",
    "    del embed_model\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return {\"agreement\": agreement_scores, \"refurbished\": refurbished_labels}\n",
    "\n",
    "class SimpleCachedDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        # Runtime transforms are not implemented in this simple cached dataset.\n",
    "        self.data = tuple([x for x in dataset])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i]\n",
    "\n",
    "class PreprocessedDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Cache preprocessed tensors - apply transforms once and store results.\n",
    "    \n",
    "    PERFORMANCE OPTIMIZATION:\n",
    "    - Applies deterministic transforms (ToImage, Resize) once at startup\n",
    "    - Stores uint8 tensors (4x less memory than float32)\n",
    "    - Random augmentations applied at runtime each epoch\n",
    "    - Test set only needs normalization at runtime (huge speedup!)\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, transform):\n",
    "        print(f\"Preprocessing {len(dataset)} images (this happens once)...\")\n",
    "        self.data = []\n",
    "        self.targets = []\n",
    "        \n",
    "        for img, target in tqdm(dataset, desc=\"Caching\", leave=False):\n",
    "            transformed = transform(img)\n",
    "            self.data.append(transformed)\n",
    "            self.targets.append(target)\n",
    "        \n",
    "        print(f\"Cached {len(self.data)} preprocessed images\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i], self.targets[i]\n",
    "\n",
    "class RefinedAugmentationWrapper(Dataset):\n",
    "    def __init__(self, preprocessed_dataset, runtime_transforms, refinement_map=None, alpha=0.4):\n",
    "        self.dataset = preprocessed_dataset\n",
    "        self.runtime_transforms = runtime_transforms\n",
    "        self.refinement_map = refinement_map\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        img_tensor, original_target = self.dataset[i]\n",
    "        if self.runtime_transforms is not None:\n",
    "            img_tensor = self.runtime_transforms(img_tensor)\n",
    "        \n",
    "        # Default: Hard label, full weight\n",
    "        target_a = original_target\n",
    "        target_b = original_target\n",
    "        lam_target = 1.0\n",
    "        weight = 1.0 \n",
    "\n",
    "        if self.refinement_map is not None:\n",
    "            score = self.refinement_map[\"agreement\"][i]\n",
    "            refurbished = int(self.refinement_map[\"refurbished\"][i])\n",
    "            \n",
    "            # SOFT LABELING LOGIC\n",
    "            # If k-NN and Original disagree (Noise/Overlap), we blend them.\n",
    "            if score < 0.7:\n",
    "                target_a = original_target\n",
    "                target_b = refurbished\n",
    "                lam_target = 1.0 - self.alpha  # e.g., 0.6 original, 0.4 refurbished\n",
    "                weight = max(score, 0.4)       # Loss is scaled by k-NN confidence\n",
    "            else:\n",
    "                # Highly stable samples\n",
    "                target_a = original_target\n",
    "                target_b = original_target\n",
    "                lam_target = 1.0\n",
    "                weight = 1.0\n",
    "                \n",
    "        # We return two targets and a lambda to handle the \"Soft Label\" in the loss function\n",
    "        return img_tensor, target_a, target_b, lam_target, weight\n",
    "\n",
    "class CIFAR100_noisy_fine(Dataset):\n",
    "    \"\"\"\n",
    "    See https://github.com/UCSC-REAL/cifar-10-100n, https://www.noisylabels.com/ and `Learning with Noisy Labels\n",
    "    Revisited: A Study Using Real-World Human Annotations`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, root: str, train: bool, transform: Optional[Callable], download: bool\n",
    "    ):\n",
    "        cifar100 = CIFAR100(\n",
    "            root=root, train=train, transform=None, download=download\n",
    "        )\n",
    "        data, targets = tuple(zip(*cifar100))\n",
    "\n",
    "        if train:\n",
    "            noisy_label_file = os.path.join(root, \"CIFAR-100-noisy.npz\")\n",
    "            if not os.path.isfile(noisy_label_file):\n",
    "                raise FileNotFoundError(\n",
    "                    f\"{type(self).__name__} need {noisy_label_file} to be used!\"\n",
    "                )\n",
    "\n",
    "            noise_file = np.load(noisy_label_file)\n",
    "            if not np.array_equal(noise_file[\"clean_label\"], targets):\n",
    "                raise RuntimeError(\"Clean labels do not match!\")\n",
    "            targets = noise_file[\"noisy_label\"]\n",
    "\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, i: int):\n",
    "        return self.data[i], self.targets[i]\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping to stop training when validation metric doesn't improve.\"\"\"\n",
    "    def __init__(self, patience=10, min_delta=0.0, mode='max'):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.best_epoch = 0\n",
    "        \n",
    "    def __call__(self, score, epoch):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_epoch = epoch\n",
    "            return False\n",
    "        \n",
    "        if self.mode == 'max':\n",
    "            # For accuracy (higher is better)\n",
    "            if score > self.best_score + self.min_delta:\n",
    "                self.best_score = score\n",
    "                self.best_epoch = epoch\n",
    "                self.counter = 0\n",
    "            else:\n",
    "                self.counter += 1\n",
    "        else:\n",
    "            # For loss (lower is better)\n",
    "            if score < self.best_score - self.min_delta:\n",
    "                self.best_score = score\n",
    "                self.best_epoch = epoch\n",
    "                self.counter = 0\n",
    "            else:\n",
    "                self.counter += 1\n",
    "        \n",
    "        if self.counter >= self.patience:\n",
    "            self.early_stop = True\n",
    "        \n",
    "        return self.early_stop\n",
    "\n",
    "\n",
    "# === PREPROCESSING (applied once and cached) ===\n",
    "# Only deterministic, spatial transforms - stores uint8 tensors (saves memory!)\n",
    "preprocess_transforms = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.Resize(config[\"upscale_size\"]),  # Upscale from 32x32 to 128x128\n",
    "])\n",
    "\n",
    "# === RUNTIME AUGMENTATION (applied at each epoch) ===\n",
    "# Random transforms for training (includes normalization at the end)\n",
    "train_runtime_transforms = v2.Compose([\n",
    "    v2.RandomCrop(config[\"upscale_size\"], padding=4),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    v2.RandomRotation(15),\n",
    "    v2.ToDtype(torch.float32, scale=True),  # Convert to float [0,1]\n",
    "    v2.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),  # CIFAR-100 stats\n",
    "    v2.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3))\n",
    "])\n",
    "\n",
    "# Test set: only normalization needed (spatial transforms already done)\n",
    "test_runtime_transforms = v2.Compose([\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "# Load raw datasets\n",
    "print(\"Loading datasets...\")\n",
    "train_set_raw = CIFAR100_noisy_fine('/kaggle/input/fii-atnn-2025-project-noisy-cifar-100/fii-atnn-2024-project-noisy-cifar-100', download=False, train=True, transform=None)\n",
    "test_set_raw = CIFAR100_noisy_fine('/kaggle/input/fii-atnn-2025-project-noisy-cifar-100/fii-atnn-2024-project-noisy-cifar-100', download=False, train=False, transform=None)\n",
    "\n",
    "# Cache raw PIL images (fast, lightweight)\n",
    "train_set_cached = SimpleCachedDataset(train_set_raw)\n",
    "test_set_cached = SimpleCachedDataset(test_set_raw)\n",
    "\n",
    "# Preprocess and cache as tensors (done once!)\n",
    "print(\"\\n[TRAIN SET]\")\n",
    "train_set_preprocessed = PreprocessedDataset(train_set_cached, preprocess_transforms)\n",
    "print(\"\\n[TEST SET]\")\n",
    "test_set_preprocessed = PreprocessedDataset(test_set_cached, preprocess_transforms)\n",
    "\n",
    "refinement_map = get_refinement_metadata(train_set_raw, device)\n",
    "\n",
    "# Add runtime augmentations (applied each epoch for train, none for test)\n",
    "train_set = RefinedAugmentationWrapper(train_set_preprocessed, train_runtime_transforms, refinement_map=refinement_map)\n",
    "test_set = RefinedAugmentationWrapper(test_set_preprocessed, test_runtime_transforms)\n",
    "\n",
    "print(f\"\\nTrain set ready: {len(train_set)} samples (with runtime augmentation)\")\n",
    "print(f\"Test set ready: {len(test_set)} samples (fully cached)\\n\")\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=config[\"batch_size\"], shuffle=True, pin_memory=pin_memory,num_workers=2,persistent_workers=True)\n",
    "test_loader = DataLoader(test_set, batch_size=500, pin_memory=pin_memory,num_workers=2,persistent_workers=True)\n",
    "\n",
    "# Load ResNet18 pretrained on ImageNet\n",
    "print(f\"Loading model: {config['model']} (pretrained on {config['pretrained']})\")\n",
    "model = timm.create_model(config[\"model\"], pretrained=True, num_classes=100)\n",
    "model = model.to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\\n\")\n",
    "\n",
    "# Label smoothing helps with noisy labels\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=config[\"label_smoothing\"])\n",
    "\n",
    "# Create optimizer based on config\n",
    "if config[\"optimizer\"].lower() == \"adamw\":\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config[\"lr\"],\n",
    "        weight_decay=config[\"weight_decay\"],\n",
    "        fused=True\n",
    "    )\n",
    "    print(f\"Optimizer: AdamW (lr={config['lr']}, weight_decay={config['weight_decay']})\")\n",
    "elif config[\"optimizer\"].lower() == \"sgd\":\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(), \n",
    "        lr=config[\"lr\"],\n",
    "        momentum=config[\"momentum\"],\n",
    "        weight_decay=config[\"weight_decay\"],\n",
    "        nesterov=config[\"nesterov\"],\n",
    "        fused=True\n",
    "    )\n",
    "    print(f\"Optimizer: SGD (lr={config['lr']}, momentum={config['momentum']}, weight_decay={config['weight_decay']}, nesterov={config['nesterov']})\")\n",
    "else:\n",
    "    raise ValueError(f\"Unknown optimizer: {config['optimizer']}. Supported: 'sgd', 'adamw'\")\n",
    "\n",
    "# Learning rate scheduler\n",
    "if config[\"scheduler\"] == \"steplr\":\n",
    "    scheduler = optim.lr_scheduler.StepLR(\n",
    "        optimizer,\n",
    "        step_size=config.get(\"step_size\", 30),\n",
    "        gamma=config.get(\"gamma\", 0.1)\n",
    "    )\n",
    "    print(f\"Scheduler: StepLR (step_size={config.get('step_size', 30)}, gamma={config.get('gamma', 0.1)})\")\n",
    "\n",
    "elif config[\"scheduler\"] == \"cosine\":\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        T_max=config[\"epochs\"],\n",
    "        eta_min=config.get(\"cosine_eta_min\", 1e-6)\n",
    "    )\n",
    "    print(f\"Scheduler: CosineAnnealingLR (T_max={config['epochs']}, eta_min={config['cosine_eta_min']})\")\n",
    "\n",
    "elif config[\"scheduler\"] == \"warm_restarts\":\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer,\n",
    "        T_0=config[\"warm_restarts_T0\"],         \n",
    "        T_mult=config.get(\"warm_restarts_mult\", 1), \n",
    "        eta_min=config.get(\"cosine_eta_min\", 1e-6)\n",
    "    )\n",
    "    # Highlight the per-batch setting so you know it's active\n",
    "    step_mode = \"Per-Batch\" if config.get(\"scheduler_step_per_batch\") else \"Per-Epoch\"\n",
    "    print(f\"Scheduler: WarmRestarts (T_0={config['warm_restarts_T0']}, T_mult={config['warm_restarts_mult']}, Step: {step_mode})\")\n",
    "\n",
    "else:\n",
    "    scheduler = None\n",
    "    print(\"Scheduler: None\")\n",
    "\n",
    "# === CUTMIX HELPER FUNCTION ===\n",
    "def rand_bbox(size, lam):\n",
    "    \"\"\"Generates a random bounding box for CutMix.\"\"\"\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "loss_threshold = config[\"loss_threshold\"]\n",
    "\n",
    "def train(epoch):\n",
    "    print(f\"\\nEpoch {epoch+1}/{config['epochs']}\")\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "    global loss_threshold\n",
    "    \n",
    "    initial_batch_count = 0 \n",
    "    use_cutmix = epoch >= config[\"switch_epoch\"]\n",
    "    aug_mode = \"CutMix\" if use_cutmix else \"MixUp\"\n",
    "    \n",
    "    # Note: Updated unpack to include target_a, target_b, and lam_target\n",
    "    for batch_idx, (inputs, t_a, t_b, lam_t, weights) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device, non_blocking=True)\n",
    "        t_a = t_a.to(device, non_blocking=True)\n",
    "        t_b = t_b.to(device, non_blocking=True)\n",
    "        lam_t = lam_t.unsqueeze(1).to(device, non_blocking=True) # [B, 1]\n",
    "        weights = weights.to(device, non_blocking=True)\n",
    "        \n",
    "        initial_batch_count += inputs.size(0)\n",
    "\n",
    "        # 1. Dynamic Filtering (Optional, keep for extreme outliers)\n",
    "        if epoch >= config[\"warmup_epochs\"]:\n",
    "            with torch.no_grad():\n",
    "                with torch.autocast(device.type, enabled=enable_half):\n",
    "                    raw_outputs = model(inputs)\n",
    "                    # Use t_a as primary for loss filtering\n",
    "                    sample_losses = F.cross_entropy(raw_outputs, t_a, reduction='none')\n",
    "                mask = sample_losses < loss_threshold\n",
    "            if mask.sum() < 2: continue\n",
    "            inputs, t_a, t_b, lam_t, weights = inputs[mask], t_a[mask], t_b[mask], lam_t[mask], weights[mask]\n",
    "\n",
    "        # 2. Augmentation (MixUp/CutMix)\n",
    "        rand_index = torch.randperm(inputs.size(0)).to(device)\n",
    "        lam_aug = np.random.beta(config[\"aug_alpha\"], config[\"aug_alpha\"])\n",
    "\n",
    "        if use_cutmix:\n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(inputs.size(), lam_aug)\n",
    "            lam_aug = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (inputs.size()[-1] * inputs.size()[-2]))\n",
    "            inputs[:, :, bbx1:bbx2, bby1:bby2] = inputs[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "        else:\n",
    "            inputs = lam_aug * inputs + (1 - lam_aug) * inputs[rand_index, :]\n",
    "\n",
    "        # 3. Forward & Soft-Loss\n",
    "        with torch.autocast(device.type, enabled=enable_half):\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Combine the two internal soft targets (Original vs Refurbished)\n",
    "            # Loss = lam_aug * (lam_t*loss(t_a) + (1-lam_t)*loss(t_b)) + (1-lam_aug)*MixedSamples...\n",
    "            def get_soft_loss(out, target_a, target_b, l_t):\n",
    "                return l_t.view(-1) * criterion(out, target_a) + (1 - l_t.view(-1)) * criterion(out, target_b)\n",
    "\n",
    "            loss_current = get_soft_loss(outputs, t_a, t_b, lam_t)\n",
    "            loss_shuffled = get_soft_loss(outputs, t_a[rand_index], t_b[rand_index], lam_t[rand_index])\n",
    "            \n",
    "            mixed_loss = lam_aug * loss_current + (1 - lam_aug) * loss_shuffled\n",
    "            \n",
    "            # Apply k-NN weights and mean\n",
    "            batch_weights = lam_aug * weights + (1 - lam_aug) * weights[rand_index]\n",
    "            loss = (mixed_loss * batch_weights).mean()\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if config.get(\"scheduler_step_per_batch\") and scheduler is not None:\n",
    "            scheduler.step(epoch + batch_idx / len(train_loader))\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        total += t_a.size(0)\n",
    "        correct += outputs.argmax(1).eq(t_a).sum().item()\n",
    "\n",
    "    if epoch >= config[\"warmup_epochs\"]:\n",
    "        loss_threshold *= config[\"dynamic_threshold_decay\"]\n",
    "    \n",
    "    epoch_acc = 100.0 * correct / total\n",
    "    keep_rate = (total / initial_batch_count) * 100\n",
    "    print(f\"Keep Rate: {keep_rate:.2f}% | Threshold: {loss_threshold:.4f} | Mode: {aug_mode}\")\n",
    "    return running_loss / total, epoch_acc, aug_mode\n",
    "\n",
    "@torch.inference_mode()\n",
    "def val():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, t_a, t_b, lam_t, _ in test_loader:\n",
    "        inputs, targets = inputs.to(device), t_a.to(device)\n",
    "        with torch.autocast(device.type, enabled=enable_half):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        predicted = outputs.argmax(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100.0 * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "@torch.inference_mode()\n",
    "def inference():\n",
    "    model.eval()\n",
    "    \n",
    "    labels = []\n",
    "    \n",
    "    for inputs, _, _, _, _ in test_loader:\n",
    "        inputs = inputs.to(device, non_blocking=True)\n",
    "        with torch.autocast(device.type, enabled=enable_half):\n",
    "            outputs = model(inputs)\n",
    "\n",
    "        predicted = outputs.argmax(1).tolist()\n",
    "        labels.extend(predicted)\n",
    "    \n",
    "    return labels\n",
    "\n",
    "# Initialize WandB\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "run_name = f\"cifar100noisy_{config['model']}_{config['optimizer']}_lr{config['lr']}_bs{config['batch_size']}_{timestamp}\"\n",
    "\n",
    "# wandb.init(\n",
    "#     project=config[\"wandb_project\"],\n",
    "#     name=run_name,\n",
    "#     config=config\n",
    "# )\n",
    "\n",
    "best = 0.0\n",
    "best_epoch = 0\n",
    "\n",
    "# Initialize early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    patience=config[\"early_stop_patience\"],\n",
    "    min_delta=config[\"early_stop_min_delta\"],\n",
    "    mode=config[\"early_stop_mode\"]\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Starting Training - {config['epochs']} epochs\")\n",
    "print(f\"Model: {config['model']} (pretrained on {config['pretrained']})\")\n",
    "print(f\"Optimizer: {config['optimizer'].upper()}, LR: {config['lr']}, Batch Size: {config['batch_size']}\")\n",
    "if config[\"optimizer\"].lower() == \"sgd\":\n",
    "    print(f\"Momentum: {config['momentum']}, Nesterov: {config['nesterov']}\")\n",
    "print(f\"Weight Decay: {config['weight_decay']}, Label Smoothing: {config['label_smoothing']}\")\n",
    "print(f\"Scheduler: {config['scheduler']}\")\n",
    "print(f\"Early Stopping: Enabled (patience={config['early_stop_patience']}, mode={config['early_stop_mode']})\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "with tqdm(range(config[\"epochs\"])) as tbar:\n",
    "    for epoch in tbar:\n",
    "        # 1. Run Train (includes internal per-batch scheduler steps)\n",
    "        train_loss, train_acc, mode = train(epoch)\n",
    "        \n",
    "        # 2. Run Validation\n",
    "        val_loss, val_acc = val()\n",
    "        \n",
    "        # 3. Handle LR logging (step only if NOT per-batch)\n",
    "        if scheduler is not None:\n",
    "            if not config.get(\"scheduler_step_per_batch\"):\n",
    "                scheduler.step()\n",
    "            current_lr = scheduler.get_last_lr()[0]\n",
    "        else:\n",
    "            current_lr = config[\"lr\"]\n",
    "        \n",
    "        # 4. Checkpointing\n",
    "        if val_acc > best:\n",
    "            best = val_acc\n",
    "            best_epoch = epoch\n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_acc': val_acc,\n",
    "                'val_loss': val_loss,\n",
    "            }\n",
    "            if scheduler is not None:\n",
    "                checkpoint['scheduler_state_dict'] = scheduler.state_dict()\n",
    "            torch.save(checkpoint, './best_model.pth')\n",
    "        \n",
    "        # 5. Update Progress Bar & Console\n",
    "        status = f\"Epoch {epoch+1}/{config['epochs']} | Train: {train_acc:.2f}% | Val: {val_acc:.2f}% | Best: {best:.2f}% | LR: {current_lr:.6f}\"\n",
    "        tbar.set_description(status)\n",
    "        print(status)\n",
    "        \n",
    "        # 6. Early stopping check\n",
    "        if early_stopping(val_acc, epoch):\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "            print(f\"Best Val Accuracy: {best:.2f}% at epoch {best_epoch+1}\")\n",
    "            print(f\"{'='*60}\\n\")\n",
    "            break\n",
    "    \n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Training Complete!\")\n",
    "print(f\"Best Val Accuracy: {best:.2f}% at epoch {best_epoch+1}\")\n",
    "print(f\"Loading best model for inference...\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Load best model for inference\n",
    "checkpoint = torch.load('./best_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Best model loaded (Epoch {checkpoint['epoch']+1}, Val Acc: {checkpoint['val_acc']:.2f}%)\\n\")\n",
    "\n",
    "# Generate submission\n",
    "data = {\n",
    "    \"ID\": [],\n",
    "    \"target\": []\n",
    "}\n",
    "\n",
    "print(\"Generating predictions...\")\n",
    "for i, label in enumerate(inference()):\n",
    "    data[\"ID\"].append(i)\n",
    "    data[\"target\"].append(label)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"/kaggle/working/submission.csv\", index=False)\n",
    "\n",
    "# Log final results to WandB\n",
    "# wandb.summary[\"final_best_val_acc\"] = best\n",
    "# wandb.summary[\"best_epoch\"] = best_epoch\n",
    "# wandb.summary[\"total_epochs\"] = config[\"epochs\"]\n",
    "# if scheduler is not None:\n",
    "#     wandb.summary[\"final_lr\"] = scheduler.get_last_lr()[0]\n",
    "# else:\n",
    "#     wandb.summary[\"final_lr\"] = config[\"lr\"]\n",
    "# wandb.summary[\"early_stopped\"] = early_stopping.early_stop\n",
    "# wandb.summary[\"epochs_trained\"] = best_epoch + 1 if early_stopping.early_stop else config[\"epochs\"]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Submission saved to: ./submission.csv\")\n",
    "print(f\"Best model saved to: ./best_model.pth\")\n",
    "print(f\"Best Val Accuracy: {best:.2f}% (Epoch {best_epoch+1})\")\n",
    "if early_stopping.early_stop:\n",
    "    print(f\"Training stopped early (patience reached)\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Finish WandB run\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14551506,
     "sourceId": 123776,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30776,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19297.361382,
   "end_time": "2026-01-08T21:50:30.456816",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-08T16:28:53.095434",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "26b74cbeb58848d1a880fecc4484fd38": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2f90d1ae9ef64dd8ac3786fa47ce0057": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e243219addf54781ac6e6a9223e6f15f",
       "max": 46807446.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8bb2d8ca6d004143b28011dfb92a357a",
       "value": 46807446.0
      }
     },
     "53c0ab4a6ad4432f975c3c172210cdbb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5cdc63b42e6340c7aa6e527707738535": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "65b4556438fa425ba0dbc6d7926bcba2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a89489d5fb6f419cb765723f6718d0e5",
        "IPY_MODEL_2f90d1ae9ef64dd8ac3786fa47ce0057",
        "IPY_MODEL_8508c3be342b4029b63da4b94bc8ad55"
       ],
       "layout": "IPY_MODEL_26b74cbeb58848d1a880fecc4484fd38"
      }
     },
     "8508c3be342b4029b63da4b94bc8ad55": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c9927be92355497b8799dbdc74f585f5",
       "placeholder": "​",
       "style": "IPY_MODEL_53c0ab4a6ad4432f975c3c172210cdbb",
       "value": " 46.8M/46.8M [00:00&lt;00:00, 143MB/s]"
      }
     },
     "8bb2d8ca6d004143b28011dfb92a357a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a89489d5fb6f419cb765723f6718d0e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d4de1c2e032a4fbfa6438579440b1033",
       "placeholder": "​",
       "style": "IPY_MODEL_5cdc63b42e6340c7aa6e527707738535",
       "value": "model.safetensors: 100%"
      }
     },
     "c9927be92355497b8799dbdc74f585f5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d4de1c2e032a4fbfa6438579440b1033": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e243219addf54781ac6e6a9223e6f15f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
