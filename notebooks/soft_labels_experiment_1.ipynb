{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc3ac002",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-10T15:10:45.549925Z",
     "iopub.status.busy": "2026-01-10T15:10:45.549440Z",
     "iopub.status.idle": "2026-01-10T20:42:58.178212Z",
     "shell.execute_reply": "2026-01-10T20:42:58.176967Z"
    },
    "papermill": {
     "duration": 19932.635517,
     "end_time": "2026-01-10T20:42:58.180234",
     "exception": false,
     "start_time": "2026-01-10T15:10:45.544717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading datasets...\n",
      "\n",
      "[TRAIN SET]\n",
      "Preprocessing 50000 images (this happens once)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cached 50000 preprocessed images\n",
      "\n",
      "[TEST SET]\n",
      "Preprocessing 10000 images (this happens once)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cached 10000 preprocessed images\n",
      "\n",
      "Extracting Features for Analysis...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5d47f438b134433a63d54bf7b0c0e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/46.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing Data: 100%|██████████| 50000/50000 [04:05<00:00, 203.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running k-NN Agreement & Class Balancing...\n",
      "\n",
      "Train set ready: 50000 samples (with runtime augmentation)\n",
      "Test set ready: 10000 samples (fully cached)\n",
      "\n",
      "Loading model: resnet18 (pretrained on imagenet)\n",
      "Total parameters: 11,227,812\n",
      "Trainable parameters: 11,227,812\n",
      "\n",
      "Optimizer: AdamW (lr=0.001, weight_decay=0.02)\n",
      "Scheduler: WarmRestarts (T_0=25, T_mult=1, Step: Per-Batch)\n",
      "\n",
      "======================================================================\n",
      "Starting Training - 100 epochs\n",
      "Model: resnet18 (pretrained on imagenet)\n",
      "Optimizer: ADAMW, LR: 0.001, Batch Size: 128\n",
      "Weight Decay: 0.02, Label Smoothing: 0.1\n",
      "Scheduler: warm_restarts\n",
      "Early Stopping: Enabled (patience=35, mode=max)\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n",
      "Keep Rate: 100.00% | Alpha: 0.350 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | Train: 14.81% | Val: 54.61% | Best: 54.61% | LR: 0.000996:   1%|          | 1/100 [04:15<7:00:57, 255.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | Train: 14.81% | Val: 54.61% | Best: 54.61% | LR: 0.000996\n",
      "\n",
      "Epoch 2/100\n",
      "Keep Rate: 100.00% | Alpha: 0.355 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 | Train: 23.10% | Val: 60.55% | Best: 60.55% | LR: 0.000984:   2%|▏         | 2/100 [08:20<6:47:24, 249.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 | Train: 23.10% | Val: 60.55% | Best: 60.55% | LR: 0.000984\n",
      "\n",
      "Epoch 3/100\n",
      "Keep Rate: 100.00% | Alpha: 0.360 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 | Train: 24.43% | Val: 63.54% | Best: 63.54% | LR: 0.000965:   3%|▎         | 3/100 [12:26<6:40:54, 247.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 | Train: 24.43% | Val: 63.54% | Best: 63.54% | LR: 0.000965\n",
      "\n",
      "Epoch 4/100\n",
      "Keep Rate: 100.00% | Alpha: 0.365 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 | Train: 23.85% | Val: 65.54% | Best: 65.54% | LR: 0.000939:   4%|▍         | 4/100 [16:34<6:36:37, 247.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 | Train: 23.85% | Val: 65.54% | Best: 65.54% | LR: 0.000939\n",
      "\n",
      "Epoch 5/100\n",
      "Keep Rate: 100.00% | Alpha: 0.370 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 | Train: 26.19% | Val: 66.23% | Best: 66.23% | LR: 0.000906:   5%|▌         | 5/100 [20:40<6:31:33, 247.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 | Train: 26.19% | Val: 66.23% | Best: 66.23% | LR: 0.000906\n",
      "\n",
      "Epoch 6/100\n",
      "Keep Rate: 69.30% | Alpha: 0.375 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 | Train: 33.55% | Val: 66.03% | Best: 66.23% | LR: 0.000866:   6%|▌         | 6/100 [25:01<6:34:44, 251.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 | Train: 33.55% | Val: 66.03% | Best: 66.23% | LR: 0.000866\n",
      "\n",
      "Epoch 7/100\n",
      "Keep Rate: 69.29% | Alpha: 0.380 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 | Train: 35.96% | Val: 66.42% | Best: 66.42% | LR: 0.000821:   7%|▋         | 7/100 [29:09<6:28:27, 250.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 | Train: 35.96% | Val: 66.42% | Best: 66.42% | LR: 0.000821\n",
      "\n",
      "Epoch 8/100\n",
      "Keep Rate: 69.91% | Alpha: 0.385 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 | Train: 39.93% | Val: 67.32% | Best: 67.32% | LR: 0.000770:   8%|▊         | 8/100 [33:17<6:22:53, 249.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 | Train: 39.93% | Val: 67.32% | Best: 67.32% | LR: 0.000770\n",
      "\n",
      "Epoch 9/100\n",
      "Keep Rate: 70.45% | Alpha: 0.390 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 | Train: 35.30% | Val: 68.35% | Best: 68.35% | LR: 0.000716:   9%|▉         | 9/100 [37:23<6:17:03, 248.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 | Train: 35.30% | Val: 68.35% | Best: 68.35% | LR: 0.000716\n",
      "\n",
      "Epoch 10/100\n",
      "Keep Rate: 70.74% | Alpha: 0.395 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 | Train: 38.01% | Val: 68.33% | Best: 68.35% | LR: 0.000658:  10%|█         | 10/100 [41:30<6:11:58, 247.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 | Train: 38.01% | Val: 68.33% | Best: 68.35% | LR: 0.000658\n",
      "\n",
      "Epoch 11/100\n",
      "Keep Rate: 71.19% | Alpha: 0.400 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 | Train: 34.19% | Val: 68.65% | Best: 68.65% | LR: 0.000598:  11%|█         | 11/100 [45:37<6:07:22, 247.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 | Train: 34.19% | Val: 68.65% | Best: 68.65% | LR: 0.000598\n",
      "\n",
      "Epoch 12/100\n",
      "Keep Rate: 71.47% | Alpha: 0.405 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 | Train: 37.24% | Val: 69.38% | Best: 69.38% | LR: 0.000536:  12%|█▏        | 12/100 [49:43<6:02:35, 247.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 | Train: 37.24% | Val: 69.38% | Best: 69.38% | LR: 0.000536\n",
      "\n",
      "Epoch 13/100\n",
      "Keep Rate: 71.90% | Alpha: 0.410 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 | Train: 42.83% | Val: 70.25% | Best: 70.25% | LR: 0.000474:  13%|█▎        | 13/100 [53:50<5:58:19, 247.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 | Train: 42.83% | Val: 70.25% | Best: 70.25% | LR: 0.000474\n",
      "\n",
      "Epoch 14/100\n",
      "Keep Rate: 72.30% | Alpha: 0.415 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 | Train: 39.11% | Val: 70.02% | Best: 70.25% | LR: 0.000412:  14%|█▍        | 14/100 [57:56<5:53:47, 246.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 | Train: 39.11% | Val: 70.02% | Best: 70.25% | LR: 0.000412\n",
      "\n",
      "Epoch 15/100\n",
      "Keep Rate: 72.65% | Alpha: 0.420 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100 | Train: 41.34% | Val: 69.65% | Best: 70.25% | LR: 0.000352:  15%|█▌        | 15/100 [1:02:03<5:49:38, 246.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100 | Train: 41.34% | Val: 69.65% | Best: 70.25% | LR: 0.000352\n",
      "\n",
      "Epoch 16/100\n",
      "Keep Rate: 72.79% | Alpha: 0.425 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100 | Train: 38.96% | Val: 70.03% | Best: 70.25% | LR: 0.000294:  16%|█▌        | 16/100 [1:06:09<5:45:30, 246.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100 | Train: 38.96% | Val: 70.03% | Best: 70.25% | LR: 0.000294\n",
      "\n",
      "Epoch 17/100\n",
      "Keep Rate: 73.09% | Alpha: 0.430 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100 | Train: 38.31% | Val: 70.17% | Best: 70.25% | LR: 0.000240:  17%|█▋        | 17/100 [1:10:17<5:41:31, 246.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100 | Train: 38.31% | Val: 70.17% | Best: 70.25% | LR: 0.000240\n",
      "\n",
      "Epoch 18/100\n",
      "Keep Rate: 73.23% | Alpha: 0.435 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100 | Train: 40.79% | Val: 70.42% | Best: 70.42% | LR: 0.000190:  18%|█▊        | 18/100 [1:14:23<5:37:08, 246.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100 | Train: 40.79% | Val: 70.42% | Best: 70.42% | LR: 0.000190\n",
      "\n",
      "Epoch 19/100\n",
      "Keep Rate: 73.27% | Alpha: 0.440 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100 | Train: 39.82% | Val: 70.49% | Best: 70.49% | LR: 0.000144:  19%|█▉        | 19/100 [1:18:31<5:33:34, 247.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100 | Train: 39.82% | Val: 70.49% | Best: 70.49% | LR: 0.000144\n",
      "\n",
      "Epoch 20/100\n",
      "Keep Rate: 73.45% | Alpha: 0.445 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100 | Train: 43.48% | Val: 70.94% | Best: 70.94% | LR: 0.000105:  20%|██        | 20/100 [1:22:37<5:29:16, 246.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100 | Train: 43.48% | Val: 70.94% | Best: 70.94% | LR: 0.000105\n",
      "\n",
      "Epoch 21/100\n",
      "Keep Rate: 73.60% | Alpha: 0.450 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100 | Train: 40.06% | Val: 70.84% | Best: 70.94% | LR: 0.000071:  21%|██        | 21/100 [1:26:44<5:25:03, 246.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100 | Train: 40.06% | Val: 70.84% | Best: 70.94% | LR: 0.000071\n",
      "\n",
      "Epoch 22/100\n",
      "Keep Rate: 73.74% | Alpha: 0.455 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100 | Train: 44.22% | Val: 71.32% | Best: 71.32% | LR: 0.000045:  22%|██▏       | 22/100 [1:30:51<5:20:43, 246.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100 | Train: 44.22% | Val: 71.32% | Best: 71.32% | LR: 0.000045\n",
      "\n",
      "Epoch 23/100\n",
      "Keep Rate: 73.74% | Alpha: 0.460 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100 | Train: 40.00% | Val: 71.06% | Best: 71.32% | LR: 0.000026:  23%|██▎       | 23/100 [1:34:57<5:16:26, 246.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100 | Train: 40.00% | Val: 71.06% | Best: 71.32% | LR: 0.000026\n",
      "\n",
      "Epoch 24/100\n",
      "Keep Rate: 73.74% | Alpha: 0.465 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100 | Train: 43.10% | Val: 70.99% | Best: 71.32% | LR: 0.000014:  24%|██▍       | 24/100 [1:39:02<5:11:54, 246.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100 | Train: 43.10% | Val: 70.99% | Best: 71.32% | LR: 0.000014\n",
      "\n",
      "Epoch 25/100\n",
      "Keep Rate: 73.51% | Alpha: 0.470 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100 | Train: 41.75% | Val: 71.10% | Best: 71.32% | LR: 0.000010:  25%|██▌       | 25/100 [1:43:06<5:06:48, 245.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100 | Train: 41.75% | Val: 71.10% | Best: 71.32% | LR: 0.000010\n",
      "\n",
      "Epoch 26/100\n",
      "Keep Rate: 71.95% | Alpha: 0.475 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100 | Train: 37.02% | Val: 68.74% | Best: 71.32% | LR: 0.000797:  26%|██▌       | 26/100 [1:47:11<5:02:46, 245.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100 | Train: 37.02% | Val: 68.74% | Best: 71.32% | LR: 0.000797\n",
      "\n",
      "Epoch 27/100\n",
      "Keep Rate: 71.92% | Alpha: 0.480 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100 | Train: 38.07% | Val: 68.33% | Best: 71.32% | LR: 0.000788:  27%|██▋       | 27/100 [1:51:20<4:59:58, 246.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100 | Train: 38.07% | Val: 68.33% | Best: 71.32% | LR: 0.000788\n",
      "\n",
      "Epoch 28/100\n",
      "Keep Rate: 71.79% | Alpha: 0.485 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100 | Train: 38.88% | Val: 68.50% | Best: 71.32% | LR: 0.000772:  28%|██▊       | 28/100 [1:55:27<4:55:47, 246.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100 | Train: 38.88% | Val: 68.50% | Best: 71.32% | LR: 0.000772\n",
      "\n",
      "Epoch 29/100\n",
      "Keep Rate: 71.92% | Alpha: 0.490 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100 | Train: 39.80% | Val: 69.18% | Best: 71.32% | LR: 0.000751:  29%|██▉       | 29/100 [1:59:34<4:51:46, 246.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100 | Train: 39.80% | Val: 69.18% | Best: 71.32% | LR: 0.000751\n",
      "\n",
      "Epoch 30/100\n",
      "Keep Rate: 72.24% | Alpha: 0.495 | Mode: MixUp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100 | Train: 40.56% | Val: 69.02% | Best: 71.32% | LR: 0.000725:  30%|███       | 30/100 [2:03:41<4:47:59, 246.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100 | Train: 40.56% | Val: 69.02% | Best: 71.32% | LR: 0.000725\n",
      "\n",
      "Epoch 31/100\n",
      "Keep Rate: 72.27% | Alpha: 0.500 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100 | Train: 56.07% | Val: 69.64% | Best: 71.32% | LR: 0.000693:  31%|███       | 31/100 [2:07:47<4:43:30, 246.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100 | Train: 56.07% | Val: 69.64% | Best: 71.32% | LR: 0.000693\n",
      "\n",
      "Epoch 32/100\n",
      "Keep Rate: 72.18% | Alpha: 0.505 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100 | Train: 56.63% | Val: 69.82% | Best: 71.32% | LR: 0.000657:  32%|███▏      | 32/100 [2:11:54<4:39:36, 246.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100 | Train: 56.63% | Val: 69.82% | Best: 71.32% | LR: 0.000657\n",
      "\n",
      "Epoch 33/100\n",
      "Keep Rate: 72.45% | Alpha: 0.510 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100 | Train: 56.04% | Val: 68.94% | Best: 71.32% | LR: 0.000617:  33%|███▎      | 33/100 [2:16:01<4:35:34, 246.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100 | Train: 56.04% | Val: 68.94% | Best: 71.32% | LR: 0.000617\n",
      "\n",
      "Epoch 34/100\n",
      "Keep Rate: 72.61% | Alpha: 0.515 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100 | Train: 56.53% | Val: 69.46% | Best: 71.32% | LR: 0.000573:  34%|███▍      | 34/100 [2:20:06<4:30:50, 246.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100 | Train: 56.53% | Val: 69.46% | Best: 71.32% | LR: 0.000573\n",
      "\n",
      "Epoch 35/100\n",
      "Keep Rate: 72.72% | Alpha: 0.520 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100 | Train: 60.82% | Val: 70.89% | Best: 71.32% | LR: 0.000527:  35%|███▌      | 35/100 [2:24:11<4:26:28, 245.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100 | Train: 60.82% | Val: 70.89% | Best: 71.32% | LR: 0.000527\n",
      "\n",
      "Epoch 36/100\n",
      "Keep Rate: 72.96% | Alpha: 0.525 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100 | Train: 58.21% | Val: 69.53% | Best: 71.32% | LR: 0.000479:  36%|███▌      | 36/100 [2:28:18<4:22:33, 246.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100 | Train: 58.21% | Val: 69.53% | Best: 71.32% | LR: 0.000479\n",
      "\n",
      "Epoch 37/100\n",
      "Keep Rate: 73.14% | Alpha: 0.530 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100 | Train: 55.67% | Val: 70.21% | Best: 71.32% | LR: 0.000430:  37%|███▋      | 37/100 [2:32:27<4:19:24, 247.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100 | Train: 55.67% | Val: 70.21% | Best: 71.32% | LR: 0.000430\n",
      "\n",
      "Epoch 38/100\n",
      "Keep Rate: 73.26% | Alpha: 0.535 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100 | Train: 59.12% | Val: 70.42% | Best: 71.32% | LR: 0.000380:  38%|███▊      | 38/100 [2:36:33<4:15:07, 246.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100 | Train: 59.12% | Val: 70.42% | Best: 71.32% | LR: 0.000380\n",
      "\n",
      "Epoch 39/100\n",
      "Keep Rate: 73.33% | Alpha: 0.540 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100 | Train: 58.60% | Val: 70.74% | Best: 71.32% | LR: 0.000331:  39%|███▉      | 39/100 [2:40:41<4:11:12, 247.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100 | Train: 58.60% | Val: 70.74% | Best: 71.32% | LR: 0.000331\n",
      "\n",
      "Epoch 40/100\n",
      "Keep Rate: 73.58% | Alpha: 0.545 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100 | Train: 60.38% | Val: 71.08% | Best: 71.32% | LR: 0.000283:  40%|████      | 40/100 [2:44:49<4:07:15, 247.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100 | Train: 60.38% | Val: 71.08% | Best: 71.32% | LR: 0.000283\n",
      "\n",
      "Epoch 41/100\n",
      "Keep Rate: 73.59% | Alpha: 0.550 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100 | Train: 58.07% | Val: 70.91% | Best: 71.32% | LR: 0.000237:  41%|████      | 41/100 [2:48:56<4:03:03, 247.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100 | Train: 58.07% | Val: 70.91% | Best: 71.32% | LR: 0.000237\n",
      "\n",
      "Epoch 42/100\n",
      "Keep Rate: 73.67% | Alpha: 0.555 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100 | Train: 60.61% | Val: 71.11% | Best: 71.32% | LR: 0.000193:  42%|████▏     | 42/100 [2:53:02<3:58:39, 246.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100 | Train: 60.61% | Val: 71.11% | Best: 71.32% | LR: 0.000193\n",
      "\n",
      "Epoch 43/100\n",
      "Keep Rate: 73.95% | Alpha: 0.560 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/100 | Train: 60.32% | Val: 71.25% | Best: 71.32% | LR: 0.000153:  43%|████▎     | 43/100 [2:57:09<3:54:44, 247.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100 | Train: 60.32% | Val: 71.25% | Best: 71.32% | LR: 0.000153\n",
      "\n",
      "Epoch 44/100\n",
      "Keep Rate: 73.97% | Alpha: 0.565 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/100 | Train: 61.91% | Val: 71.39% | Best: 71.39% | LR: 0.000117:  44%|████▍     | 44/100 [3:01:17<3:50:46, 247.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100 | Train: 61.91% | Val: 71.39% | Best: 71.39% | LR: 0.000117\n",
      "\n",
      "Epoch 45/100\n",
      "Keep Rate: 74.08% | Alpha: 0.570 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/100 | Train: 62.43% | Val: 71.29% | Best: 71.39% | LR: 0.000086:  45%|████▌     | 45/100 [3:05:25<3:46:44, 247.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100 | Train: 62.43% | Val: 71.29% | Best: 71.39% | LR: 0.000086\n",
      "\n",
      "Epoch 46/100\n",
      "Keep Rate: 74.10% | Alpha: 0.575 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/100 | Train: 61.79% | Val: 71.08% | Best: 71.39% | LR: 0.000059:  46%|████▌     | 46/100 [3:09:31<3:42:19, 247.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100 | Train: 61.79% | Val: 71.08% | Best: 71.39% | LR: 0.000059\n",
      "\n",
      "Epoch 47/100\n",
      "Keep Rate: 74.17% | Alpha: 0.580 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/100 | Train: 61.92% | Val: 71.24% | Best: 71.39% | LR: 0.000038:  47%|████▋     | 47/100 [3:13:37<3:38:00, 246.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100 | Train: 61.92% | Val: 71.24% | Best: 71.39% | LR: 0.000038\n",
      "\n",
      "Epoch 48/100\n",
      "Keep Rate: 74.19% | Alpha: 0.585 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/100 | Train: 62.55% | Val: 71.34% | Best: 71.39% | LR: 0.000022:  48%|████▊     | 48/100 [3:17:45<3:34:04, 247.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100 | Train: 62.55% | Val: 71.34% | Best: 71.39% | LR: 0.000022\n",
      "\n",
      "Epoch 49/100\n",
      "Keep Rate: 74.25% | Alpha: 0.590 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/100 | Train: 63.10% | Val: 71.37% | Best: 71.39% | LR: 0.000013:  49%|████▉     | 49/100 [3:21:52<3:29:54, 246.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100 | Train: 63.10% | Val: 71.37% | Best: 71.39% | LR: 0.000013\n",
      "\n",
      "Epoch 50/100\n",
      "Keep Rate: 74.14% | Alpha: 0.595 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/100 | Train: 59.33% | Val: 71.37% | Best: 71.39% | LR: 0.000010:  50%|█████     | 50/100 [3:25:58<3:25:40, 246.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100 | Train: 59.33% | Val: 71.37% | Best: 71.39% | LR: 0.000010\n",
      "\n",
      "Epoch 51/100\n",
      "Keep Rate: 73.24% | Alpha: 0.600 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100 | Train: 58.64% | Val: 69.99% | Best: 71.39% | LR: 0.000638:  51%|█████     | 51/100 [3:30:05<3:21:30, 246.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100 | Train: 58.64% | Val: 69.99% | Best: 71.39% | LR: 0.000638\n",
      "\n",
      "Epoch 52/100\n",
      "Keep Rate: 72.96% | Alpha: 0.600 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/100 | Train: 57.46% | Val: 70.03% | Best: 71.39% | LR: 0.000630:  52%|█████▏    | 52/100 [3:34:10<3:17:08, 246.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100 | Train: 57.46% | Val: 70.03% | Best: 71.39% | LR: 0.000630\n",
      "\n",
      "Epoch 53/100\n",
      "Keep Rate: 73.00% | Alpha: 0.600 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/100 | Train: 62.58% | Val: 69.73% | Best: 71.39% | LR: 0.000618:  53%|█████▎    | 53/100 [3:38:18<3:13:13, 246.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100 | Train: 62.58% | Val: 69.73% | Best: 71.39% | LR: 0.000618\n",
      "\n",
      "Epoch 54/100\n",
      "Keep Rate: 73.16% | Alpha: 0.600 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/100 | Train: 59.90% | Val: 69.82% | Best: 71.39% | LR: 0.000601:  54%|█████▍    | 54/100 [3:42:24<3:09:06, 246.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100 | Train: 59.90% | Val: 69.82% | Best: 71.39% | LR: 0.000601\n",
      "\n",
      "Epoch 55/100\n",
      "Keep Rate: 73.23% | Alpha: 0.600 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/100 | Train: 60.74% | Val: 69.83% | Best: 71.39% | LR: 0.000580:  55%|█████▌    | 55/100 [3:46:31<3:04:55, 246.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100 | Train: 60.74% | Val: 69.83% | Best: 71.39% | LR: 0.000580\n",
      "\n",
      "Epoch 56/100\n",
      "Keep Rate: 73.34% | Alpha: 0.600 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/100 | Train: 62.78% | Val: 69.91% | Best: 71.39% | LR: 0.000555:  56%|█████▌    | 56/100 [3:50:36<3:00:31, 246.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100 | Train: 62.78% | Val: 69.91% | Best: 71.39% | LR: 0.000555\n",
      "\n",
      "Epoch 57/100\n",
      "Keep Rate: 73.40% | Alpha: 0.600 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/100 | Train: 61.33% | Val: 70.34% | Best: 71.39% | LR: 0.000526:  57%|█████▋    | 57/100 [3:54:42<2:56:28, 246.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100 | Train: 61.33% | Val: 70.34% | Best: 71.39% | LR: 0.000526\n",
      "\n",
      "Epoch 58/100\n",
      "Keep Rate: 73.65% | Alpha: 0.600 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/100 | Train: 60.24% | Val: 69.73% | Best: 71.39% | LR: 0.000494:  58%|█████▊    | 58/100 [3:58:49<2:52:31, 246.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100 | Train: 60.24% | Val: 69.73% | Best: 71.39% | LR: 0.000494\n",
      "\n",
      "Epoch 59/100\n",
      "Keep Rate: 73.63% | Alpha: 0.600 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/100 | Train: 60.75% | Val: 69.51% | Best: 71.39% | LR: 0.000459:  59%|█████▉    | 59/100 [4:02:56<2:48:30, 246.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100 | Train: 60.75% | Val: 69.51% | Best: 71.39% | LR: 0.000459\n",
      "\n",
      "Epoch 60/100\n",
      "Keep Rate: 73.75% | Alpha: 0.600 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/100 | Train: 61.32% | Val: 69.75% | Best: 71.39% | LR: 0.000422:  60%|██████    | 60/100 [4:07:04<2:44:39, 247.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100 | Train: 61.32% | Val: 69.75% | Best: 71.39% | LR: 0.000422\n",
      "\n",
      "Epoch 61/100\n",
      "Keep Rate: 73.86% | Alpha: 0.600 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100 | Train: 60.82% | Val: 69.98% | Best: 71.39% | LR: 0.000384:  61%|██████    | 61/100 [4:11:11<2:40:36, 247.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100 | Train: 60.82% | Val: 69.98% | Best: 71.39% | LR: 0.000384\n",
      "\n",
      "Epoch 62/100\n",
      "Keep Rate: 74.01% | Alpha: 0.600 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/100 | Train: 62.31% | Val: 69.94% | Best: 71.39% | LR: 0.000345:  62%|██████▏   | 62/100 [4:15:19<2:36:38, 247.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100 | Train: 62.31% | Val: 69.94% | Best: 71.39% | LR: 0.000345\n",
      "\n",
      "Epoch 63/100\n",
      "Keep Rate: 74.16% | Alpha: 0.600 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/100 | Train: 61.68% | Val: 69.87% | Best: 71.39% | LR: 0.000305:  63%|██████▎   | 63/100 [4:19:26<2:32:28, 247.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100 | Train: 61.68% | Val: 69.87% | Best: 71.39% | LR: 0.000305\n",
      "\n",
      "Epoch 64/100\n",
      "Keep Rate: 74.20% | Alpha: 0.600 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/100 | Train: 59.42% | Val: 70.11% | Best: 71.39% | LR: 0.000266:  64%|██████▍   | 64/100 [4:23:34<2:28:20, 247.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100 | Train: 59.42% | Val: 70.11% | Best: 71.39% | LR: 0.000266\n",
      "\n",
      "Epoch 65/100\n",
      "Keep Rate: 74.19% | Alpha: 0.600 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/100 | Train: 63.70% | Val: 70.08% | Best: 71.39% | LR: 0.000228:  65%|██████▌   | 65/100 [4:27:40<2:24:02, 246.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100 | Train: 63.70% | Val: 70.08% | Best: 71.39% | LR: 0.000228\n",
      "\n",
      "Epoch 66/100\n",
      "Keep Rate: 74.48% | Alpha: 0.600 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/100 | Train: 63.18% | Val: 70.50% | Best: 71.39% | LR: 0.000191:  66%|██████▌   | 66/100 [4:31:47<2:19:57, 246.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100 | Train: 63.18% | Val: 70.50% | Best: 71.39% | LR: 0.000191\n",
      "\n",
      "Epoch 67/100\n",
      "Keep Rate: 74.54% | Alpha: 0.600 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/100 | Train: 63.83% | Val: 70.41% | Best: 71.39% | LR: 0.000156:  67%|██████▋   | 67/100 [4:35:55<2:16:04, 247.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100 | Train: 63.83% | Val: 70.41% | Best: 71.39% | LR: 0.000156\n",
      "\n",
      "Epoch 68/100\n",
      "Keep Rate: 74.52% | Alpha: 0.600 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/100 | Train: 62.41% | Val: 70.30% | Best: 71.39% | LR: 0.000124:  68%|██████▊   | 68/100 [4:40:02<2:11:50, 247.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100 | Train: 62.41% | Val: 70.30% | Best: 71.39% | LR: 0.000124\n",
      "\n",
      "Epoch 69/100\n",
      "Keep Rate: 74.67% | Alpha: 0.600 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/100 | Train: 62.68% | Val: 70.46% | Best: 71.39% | LR: 0.000095:  69%|██████▉   | 69/100 [4:44:08<2:07:34, 246.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100 | Train: 62.68% | Val: 70.46% | Best: 71.39% | LR: 0.000095\n",
      "\n",
      "Epoch 70/100\n",
      "Keep Rate: 74.65% | Alpha: 0.600 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/100 | Train: 63.80% | Val: 70.36% | Best: 71.39% | LR: 0.000070:  70%|███████   | 70/100 [4:48:14<2:03:21, 246.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100 | Train: 63.80% | Val: 70.36% | Best: 71.39% | LR: 0.000070\n",
      "\n",
      "Epoch 71/100\n",
      "Keep Rate: 74.85% | Alpha: 0.600 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/100 | Train: 63.71% | Val: 70.45% | Best: 71.39% | LR: 0.000049:  71%|███████   | 71/100 [4:52:21<1:59:16, 246.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100 | Train: 63.71% | Val: 70.45% | Best: 71.39% | LR: 0.000049\n",
      "\n",
      "Epoch 72/100\n",
      "Keep Rate: 74.78% | Alpha: 0.600 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/100 | Train: 62.57% | Val: 70.50% | Best: 71.39% | LR: 0.000032:  72%|███████▏  | 72/100 [4:56:28<1:55:08, 246.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100 | Train: 62.57% | Val: 70.50% | Best: 71.39% | LR: 0.000032\n",
      "\n",
      "Epoch 73/100\n",
      "Keep Rate: 74.73% | Alpha: 0.600 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/100 | Train: 63.57% | Val: 70.51% | Best: 71.39% | LR: 0.000020:  73%|███████▎  | 73/100 [5:00:35<1:51:00, 246.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100 | Train: 63.57% | Val: 70.51% | Best: 71.39% | LR: 0.000020\n",
      "\n",
      "Epoch 74/100\n",
      "Keep Rate: 74.72% | Alpha: 0.600 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/100 | Train: 63.09% | Val: 70.82% | Best: 71.39% | LR: 0.000012:  74%|███████▍  | 74/100 [5:04:41<1:46:55, 246.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100 | Train: 63.09% | Val: 70.82% | Best: 71.39% | LR: 0.000012\n",
      "\n",
      "Epoch 75/100\n",
      "Keep Rate: 74.70% | Alpha: 0.600 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/100 | Train: 62.61% | Val: 70.84% | Best: 71.39% | LR: 0.000010:  75%|███████▌  | 75/100 [5:08:49<1:42:52, 246.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100 | Train: 62.61% | Val: 70.84% | Best: 71.39% | LR: 0.000010\n",
      "\n",
      "Epoch 76/100\n",
      "Keep Rate: 74.08% | Alpha: 0.600 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/100 | Train: 58.72% | Val: 70.48% | Best: 71.39% | LR: 0.000510:  76%|███████▌  | 76/100 [5:12:55<1:38:42, 246.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100 | Train: 58.72% | Val: 70.48% | Best: 71.39% | LR: 0.000510\n",
      "\n",
      "Epoch 77/100\n",
      "Keep Rate: 73.94% | Alpha: 0.600 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/100 | Train: 62.43% | Val: 69.83% | Best: 71.39% | LR: 0.000504:  77%|███████▋  | 77/100 [5:17:01<1:34:31, 246.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100 | Train: 62.43% | Val: 69.83% | Best: 71.39% | LR: 0.000504\n",
      "\n",
      "Epoch 78/100\n",
      "Keep Rate: 74.00% | Alpha: 0.600 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/100 | Train: 63.37% | Val: 69.62% | Best: 71.39% | LR: 0.000494:  78%|███████▊  | 78/100 [5:21:08<1:30:24, 246.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100 | Train: 63.37% | Val: 69.62% | Best: 71.39% | LR: 0.000494\n",
      "\n",
      "Epoch 79/100\n",
      "Keep Rate: 73.89% | Alpha: 0.600 | Mode: CutMix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/100 | Train: 65.34% | Val: 69.25% | Best: 71.39% | LR: 0.000481:  78%|███████▊  | 78/100 [5:25:14<1:31:44, 250.19s/it]\n",
      "/tmp/ipykernel_24/84816894.py:620: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('./best_model.pth')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100 | Train: 65.34% | Val: 69.25% | Best: 71.39% | LR: 0.000481\n",
      "\n",
      "============================================================\n",
      "Early stopping triggered at epoch 79\n",
      "Best Val Accuracy: 71.39% at epoch 44\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Training Complete!\n",
      "Best Val Accuracy: 71.39% at epoch 44\n",
      "Loading best model for inference...\n",
      "============================================================\n",
      "\n",
      "Best model loaded (Epoch 44, Val Acc: 71.39%)\n",
      "\n",
      "Generating predictions...\n",
      "\n",
      "============================================================\n",
      "Submission saved to: ./submission.csv\n",
      "Best model saved to: ./best_model.pth\n",
      "Best Val Accuracy: 71.39% (Epoch 44)\n",
      "Training stopped early (patience reached)\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import timm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from typing import Optional, Callable\n",
    "\n",
    "from torch import nn, Tensor, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.backends import cudnn\n",
    "from torch import GradScaler\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.datasets import CIFAR100\n",
    "from torchvision.transforms import v2\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# ============ Configuration ============\n",
    "config = {\n",
    "    \"dataset\": \"cifar100_noisy\",\n",
    "    \"model\": \"resnet18\",\n",
    "    \"pretrained\": \"imagenet\",\n",
    "    \"epochs\": 100,\n",
    "    \"batch_size\": 128,\n",
    "    \"lr\": 0.001,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 0.02,\n",
    "    \"nesterov\": True,\n",
    "    \"label_smoothing\": 0.1,\n",
    "    \"optimizer\": \"adamw\",\n",
    "    \"scheduler\": \"warm_restarts\",     \n",
    "    \"warm_restarts_T0\": 25,              \n",
    "    \"warm_restarts_mult\": 1,             \n",
    "    \"cosine_eta_min\": 1e-5,\n",
    "    \"scheduler_step_per_batch\": True,\n",
    "    \"early_stop_patience\": 35,\n",
    "    \"early_stop_mode\": \"max\",\n",
    "    \"early_stop_min_delta\": 0.01,\n",
    "    \"device\": \"cuda\",\n",
    "    \"mixed_precision\": True,\n",
    "    \"wandb_project\": \"cifar100-noisy-competition\",\n",
    "    \"upscale_size\": 224,  \n",
    "    \"aug_alpha\": 0.5,          \n",
    "    \"cutmix_prob\": 1.0,        \n",
    "    \"switch_epoch\": 30,        \n",
    "    \"warmup_epochs\": 5,\n",
    "    \"loss_threshold\": 2.8,\n",
    "    \"dynamic_threshold_decay\": 0.997,\n",
    "    \"soft_alpha\": 0.45\n",
    "}\n",
    "\n",
    "device = torch.device(config[\"device\"])\n",
    "print(f\"Using device: {device}\")\n",
    "cudnn.benchmark = True\n",
    "pin_memory = True\n",
    "enable_half = config[\"mixed_precision\"]  # Disable for CPU, it is slower!\n",
    "scaler = GradScaler(device, enabled=enable_half)\n",
    "\n",
    "def get_refinement_metadata(dataset, device):\n",
    "    print(\"\\nExtracting Features for Analysis...\")\n",
    "    embed_model = timm.create_model('resnet18', pretrained=True, num_classes=0).to(device)\n",
    "    embed_model.eval()\n",
    "    \n",
    "    analysis_transform = v2.Compose([\n",
    "        v2.ToImage(), v2.Resize(224), v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    features, labels = [], np.array(dataset.targets)\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(len(dataset)), desc=\"Analyzing Data\"):\n",
    "            img, _ = dataset[i]\n",
    "            img_t = analysis_transform(img).unsqueeze(0).to(device)\n",
    "            features.append(embed_model(img_t).cpu().numpy())\n",
    "    \n",
    "    features = np.concatenate(features, axis=0)\n",
    "    \n",
    "    print(\"Running k-NN Agreement & Class Balancing...\")\n",
    "    K = 10\n",
    "    knn = NearestNeighbors(n_neighbors=K+1, metric='cosine').fit(features)\n",
    "    _, indices = knn.kneighbors(features)\n",
    "    \n",
    "    refurbished_labels = []\n",
    "    agreement_scores = []\n",
    "    for i in range(len(features)):\n",
    "        neighbor_labels = labels[indices[i, 1:]]\n",
    "        counts = np.bincount(neighbor_labels, minlength=100)\n",
    "        refurbished_labels.append(np.argmax(counts))\n",
    "        agreement_scores.append(counts[labels[i]] / K)\n",
    "    \n",
    "    agreement_scores = np.array(agreement_scores)\n",
    "    refurbished_labels = np.array(refurbished_labels)\n",
    "\n",
    "    stable_mask = agreement_scores >= 0.9\n",
    "    counts_per_class = np.bincount(labels[stable_mask], minlength=100)\n",
    "    rare_classes = np.where(counts_per_class < 20)[0] # Target classes below 20 samples\n",
    "    \n",
    "    for c in rare_classes:\n",
    "        # Bolster rare classes using medium agreement samples (above 75%)\n",
    "        potential_candidates = np.where((agreement_scores >= 0.75) & (refurbished_labels == c))[0]\n",
    "        agreement_scores[potential_candidates] = 0.95 # Promote to \"Stable\" status\n",
    "            \n",
    "    del embed_model\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return {\"agreement\": agreement_scores, \"refurbished\": refurbished_labels}\n",
    "\n",
    "class SimpleCachedDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        # Runtime transforms are not implemented in this simple cached dataset.\n",
    "        self.data = tuple([x for x in dataset])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i]\n",
    "\n",
    "class PreprocessedDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Cache preprocessed tensors - apply transforms once and store results.\n",
    "    \n",
    "    PERFORMANCE OPTIMIZATION:\n",
    "    - Applies deterministic transforms (ToImage, Resize) once at startup\n",
    "    - Stores uint8 tensors (4x less memory than float32)\n",
    "    - Random augmentations applied at runtime each epoch\n",
    "    - Test set only needs normalization at runtime (huge speedup!)\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, transform):\n",
    "        print(f\"Preprocessing {len(dataset)} images (this happens once)...\")\n",
    "        self.data = []\n",
    "        self.targets = []\n",
    "        \n",
    "        for img, target in tqdm(dataset, desc=\"Caching\", leave=False):\n",
    "            transformed = transform(img)\n",
    "            self.data.append(transformed)\n",
    "            self.targets.append(target)\n",
    "        \n",
    "        print(f\"Cached {len(self.data)} preprocessed images\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i], self.targets[i]\n",
    "\n",
    "class RefinedAugmentationWrapper(Dataset):\n",
    "    def __init__(self, preprocessed_dataset, runtime_transforms, refinement_map=None, alpha=0.4):\n",
    "        self.dataset = preprocessed_dataset\n",
    "        self.runtime_transforms = runtime_transforms\n",
    "        self.refinement_map = refinement_map\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        img_tensor, original_target = self.dataset[i]\n",
    "        if self.runtime_transforms is not None:\n",
    "            img_tensor = self.runtime_transforms(img_tensor)\n",
    "        \n",
    "        # Default: Hard label, full weight\n",
    "        target_a = original_target\n",
    "        target_b = original_target\n",
    "        lam_target = 1.0\n",
    "        weight = 1.0 \n",
    "\n",
    "        if self.refinement_map is not None:\n",
    "            score = self.refinement_map[\"agreement\"][i]\n",
    "            refurbished = int(self.refinement_map[\"refurbished\"][i])\n",
    "            \n",
    "            # SOFT LABELING LOGIC\n",
    "            # If k-NN and Original disagree (Noise/Overlap), we blend them.\n",
    "            if score < 0.7:\n",
    "                target_a = original_target\n",
    "                target_b = refurbished\n",
    "                lam_target = 1.0 - self.alpha  # e.g., 0.6 original, 0.4 refurbished\n",
    "                weight = max(score, 0.4)       # Loss is scaled by k-NN confidence\n",
    "            else:\n",
    "                # Highly stable samples\n",
    "                target_a = original_target\n",
    "                target_b = original_target\n",
    "                lam_target = 1.0\n",
    "                weight = 1.0\n",
    "                \n",
    "        # We return two targets and a lambda to handle the \"Soft Label\" in the loss function\n",
    "        return img_tensor, target_a, target_b, lam_target, weight\n",
    "\n",
    "class CIFAR100_noisy_fine(Dataset):\n",
    "    \"\"\"\n",
    "    See https://github.com/UCSC-REAL/cifar-10-100n, https://www.noisylabels.com/ and `Learning with Noisy Labels\n",
    "    Revisited: A Study Using Real-World Human Annotations`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, root: str, train: bool, transform: Optional[Callable], download: bool\n",
    "    ):\n",
    "        cifar100 = CIFAR100(\n",
    "            root=root, train=train, transform=None, download=download\n",
    "        )\n",
    "        data, targets = tuple(zip(*cifar100))\n",
    "\n",
    "        if train:\n",
    "            noisy_label_file = os.path.join(root, \"CIFAR-100-noisy.npz\")\n",
    "            if not os.path.isfile(noisy_label_file):\n",
    "                raise FileNotFoundError(\n",
    "                    f\"{type(self).__name__} need {noisy_label_file} to be used!\"\n",
    "                )\n",
    "\n",
    "            noise_file = np.load(noisy_label_file)\n",
    "            if not np.array_equal(noise_file[\"clean_label\"], targets):\n",
    "                raise RuntimeError(\"Clean labels do not match!\")\n",
    "            targets = noise_file[\"noisy_label\"]\n",
    "\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, i: int):\n",
    "        return self.data[i], self.targets[i]\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping to stop training when validation metric doesn't improve.\"\"\"\n",
    "    def __init__(self, patience=10, min_delta=0.0, mode='max'):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.best_epoch = 0\n",
    "        \n",
    "    def __call__(self, score, epoch):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_epoch = epoch\n",
    "            return False\n",
    "        \n",
    "        if self.mode == 'max':\n",
    "            # For accuracy (higher is better)\n",
    "            if score > self.best_score + self.min_delta:\n",
    "                self.best_score = score\n",
    "                self.best_epoch = epoch\n",
    "                self.counter = 0\n",
    "            else:\n",
    "                self.counter += 1\n",
    "        else:\n",
    "            # For loss (lower is better)\n",
    "            if score < self.best_score - self.min_delta:\n",
    "                self.best_score = score\n",
    "                self.best_epoch = epoch\n",
    "                self.counter = 0\n",
    "            else:\n",
    "                self.counter += 1\n",
    "        \n",
    "        if self.counter >= self.patience:\n",
    "            self.early_stop = True\n",
    "        \n",
    "        return self.early_stop\n",
    "\n",
    "\n",
    "# === PREPROCESSING (applied once and cached) ===\n",
    "# Only deterministic, spatial transforms - stores uint8 tensors (saves memory!)\n",
    "preprocess_transforms = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.Resize(config[\"upscale_size\"]),  # Upscale from 32x32 to 128x128\n",
    "])\n",
    "\n",
    "# === RUNTIME AUGMENTATION (applied at each epoch) ===\n",
    "# Random transforms for training (includes normalization at the end)\n",
    "train_runtime_transforms = v2.Compose([\n",
    "    v2.RandomCrop(config[\"upscale_size\"], padding=4),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    v2.RandomRotation(15),\n",
    "    v2.ToDtype(torch.float32, scale=True),  # Convert to float [0,1]\n",
    "    v2.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),  # CIFAR-100 stats\n",
    "    v2.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3))\n",
    "])\n",
    "\n",
    "# Test set: only normalization needed (spatial transforms already done)\n",
    "test_runtime_transforms = v2.Compose([\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "# Load raw datasets\n",
    "print(\"Loading datasets...\")\n",
    "train_set_raw = CIFAR100_noisy_fine('/kaggle/input/fii-atnn-2025-project-noisy-cifar-100/fii-atnn-2024-project-noisy-cifar-100', download=False, train=True, transform=None)\n",
    "test_set_raw = CIFAR100_noisy_fine('/kaggle/input/fii-atnn-2025-project-noisy-cifar-100/fii-atnn-2024-project-noisy-cifar-100', download=False, train=False, transform=None)\n",
    "\n",
    "# Cache raw PIL images (fast, lightweight)\n",
    "train_set_cached = SimpleCachedDataset(train_set_raw)\n",
    "test_set_cached = SimpleCachedDataset(test_set_raw)\n",
    "\n",
    "# Preprocess and cache as tensors (done once!)\n",
    "print(\"\\n[TRAIN SET]\")\n",
    "train_set_preprocessed = PreprocessedDataset(train_set_cached, preprocess_transforms)\n",
    "print(\"\\n[TEST SET]\")\n",
    "test_set_preprocessed = PreprocessedDataset(test_set_cached, preprocess_transforms)\n",
    "\n",
    "refinement_map = get_refinement_metadata(train_set_raw, device)\n",
    "\n",
    "# Add runtime augmentations (applied each epoch for train, none for test)\n",
    "train_set = RefinedAugmentationWrapper(train_set_preprocessed, train_runtime_transforms, refinement_map=refinement_map)\n",
    "test_set = RefinedAugmentationWrapper(test_set_preprocessed, test_runtime_transforms)\n",
    "\n",
    "print(f\"\\nTrain set ready: {len(train_set)} samples (with runtime augmentation)\")\n",
    "print(f\"Test set ready: {len(test_set)} samples (fully cached)\\n\")\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=config[\"batch_size\"], shuffle=True, pin_memory=pin_memory,num_workers=2,persistent_workers=True)\n",
    "test_loader = DataLoader(test_set, batch_size=500, pin_memory=pin_memory,num_workers=2,persistent_workers=True)\n",
    "\n",
    "# Load ResNet18 pretrained on ImageNet\n",
    "print(f\"Loading model: {config['model']} (pretrained on {config['pretrained']})\")\n",
    "model = timm.create_model(config[\"model\"], pretrained=True, num_classes=100)\n",
    "model = model.to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\\n\")\n",
    "\n",
    "# Label smoothing helps with noisy labels\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=config[\"label_smoothing\"])\n",
    "\n",
    "# Create optimizer based on config\n",
    "if config[\"optimizer\"].lower() == \"adamw\":\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config[\"lr\"],\n",
    "        weight_decay=config[\"weight_decay\"],\n",
    "        fused=True\n",
    "    )\n",
    "    print(f\"Optimizer: AdamW (lr={config['lr']}, weight_decay={config['weight_decay']})\")\n",
    "elif config[\"optimizer\"].lower() == \"sgd\":\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(), \n",
    "        lr=config[\"lr\"],\n",
    "        momentum=config[\"momentum\"],\n",
    "        weight_decay=config[\"weight_decay\"],\n",
    "        nesterov=config[\"nesterov\"],\n",
    "        fused=True\n",
    "    )\n",
    "    print(f\"Optimizer: SGD (lr={config['lr']}, momentum={config['momentum']}, weight_decay={config['weight_decay']}, nesterov={config['nesterov']})\")\n",
    "else:\n",
    "    raise ValueError(f\"Unknown optimizer: {config['optimizer']}. Supported: 'sgd', 'adamw'\")\n",
    "\n",
    "# Learning rate scheduler\n",
    "if config[\"scheduler\"] == \"steplr\":\n",
    "    scheduler = optim.lr_scheduler.StepLR(\n",
    "        optimizer,\n",
    "        step_size=config.get(\"step_size\", 30),\n",
    "        gamma=config.get(\"gamma\", 0.1)\n",
    "    )\n",
    "    print(f\"Scheduler: StepLR (step_size={config.get('step_size', 30)}, gamma={config.get('gamma', 0.1)})\")\n",
    "\n",
    "elif config[\"scheduler\"] == \"cosine\":\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        T_max=config[\"epochs\"],\n",
    "        eta_min=config.get(\"cosine_eta_min\", 1e-6)\n",
    "    )\n",
    "    print(f\"Scheduler: CosineAnnealingLR (T_max={config['epochs']}, eta_min={config['cosine_eta_min']})\")\n",
    "\n",
    "elif config[\"scheduler\"] == \"warm_restarts\":\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer,\n",
    "        T_0=config[\"warm_restarts_T0\"],         \n",
    "        T_mult=config.get(\"warm_restarts_mult\", 1), \n",
    "        eta_min=config.get(\"cosine_eta_min\", 1e-6)\n",
    "    )\n",
    "    # Highlight the per-batch setting so you know it's active\n",
    "    step_mode = \"Per-Batch\" if config.get(\"scheduler_step_per_batch\") else \"Per-Epoch\"\n",
    "    print(f\"Scheduler: WarmRestarts (T_0={config['warm_restarts_T0']}, T_mult={config['warm_restarts_mult']}, Step: {step_mode})\")\n",
    "\n",
    "else:\n",
    "    scheduler = None\n",
    "    print(\"Scheduler: None\")\n",
    "\n",
    "# === CUTMIX HELPER FUNCTION ===\n",
    "def rand_bbox(size, lam):\n",
    "    \"\"\"Generates a random bounding box for CutMix.\"\"\"\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "loss_threshold = config[\"loss_threshold\"]\n",
    "\n",
    "def train(epoch):\n",
    "    print(f\"\\nEpoch {epoch+1}/{config['epochs']}\")\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "    global loss_threshold\n",
    "    \n",
    "    # DYNAMIC ALPHA LOGIC\n",
    "    # Starts at 0.35 and scales to 0.60 by epoch 50\n",
    "    # This ensures we don't trust the refurbished labels until the features are sharp.\n",
    "    current_soft_alpha = 0.35 + (min(epoch, 50) / 50) * 0.25\n",
    "    train_loader.dataset.alpha = current_soft_alpha\n",
    "    \n",
    "    initial_batch_count = 0 \n",
    "    use_cutmix = epoch >= config[\"switch_epoch\"]\n",
    "    aug_mode = \"CutMix\" if use_cutmix else \"MixUp\"\n",
    "    \n",
    "    for batch_idx, (inputs, t_a, t_b, lam_t, weights) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device, non_blocking=True)\n",
    "        t_a = t_a.to(device, non_blocking=True)\n",
    "        t_b = t_b.to(device, non_blocking=True)\n",
    "        lam_t = lam_t.unsqueeze(1).to(device, non_blocking=True) \n",
    "        weights = weights.to(device, non_blocking=True)\n",
    "        \n",
    "        initial_batch_count += inputs.size(0)\n",
    "\n",
    "        # DYNAMIC FILTERING\n",
    "        if epoch >= config[\"warmup_epochs\"]:\n",
    "            with torch.no_grad():\n",
    "                with torch.autocast(device.type, enabled=enable_half):\n",
    "                    raw_outputs = model(inputs)\n",
    "                    sample_losses = F.cross_entropy(raw_outputs, t_a, reduction='none')\n",
    "                mask = sample_losses < loss_threshold\n",
    "            if mask.sum() < 2: continue\n",
    "            inputs, t_a, t_b, lam_t, weights = inputs[mask], t_a[mask], t_b[mask], lam_t[mask], weights[mask]\n",
    "\n",
    "        # AUGMENTATION\n",
    "        rand_index = torch.randperm(inputs.size(0)).to(device)\n",
    "        lam_aug = np.random.beta(config[\"aug_alpha\"], config[\"aug_alpha\"])\n",
    "\n",
    "        if use_cutmix:\n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(inputs.size(), lam_aug)\n",
    "            lam_aug = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (inputs.size()[-1] * inputs.size()[-2]))\n",
    "            inputs[:, :, bbx1:bbx2, bby1:bby2] = inputs[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "        else:\n",
    "            inputs = lam_aug * inputs + (1 - lam_aug) * inputs[rand_index, :]\n",
    "\n",
    "        # FORWARD & SOFT-LOSS\n",
    "        with torch.autocast(device.type, enabled=enable_half):\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            def get_soft_loss(out, target_a, target_b, l_t):\n",
    "                return l_t.view(-1) * criterion(out, target_a) + (1 - l_t.view(-1)) * criterion(out, target_b)\n",
    "\n",
    "            loss_current = get_soft_loss(outputs, t_a, t_b, lam_t)\n",
    "            loss_shuffled = get_soft_loss(outputs, t_a[rand_index], t_b[rand_index], lam_t[rand_index])\n",
    "            \n",
    "            mixed_loss = lam_aug * loss_current + (1 - lam_aug) * loss_shuffled\n",
    "            batch_weights = lam_aug * weights + (1 - lam_aug) * weights[rand_index]\n",
    "            loss = (mixed_loss * batch_weights).mean()\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # DECAYING WARM RESTARTS\n",
    "        if config.get(\"scheduler_step_per_batch\") and scheduler is not None:\n",
    "            cycle_idx = epoch // config[\"warm_restarts_T0\"]\n",
    "            cycle_decay = 0.8 ** cycle_idx \n",
    "            \n",
    "            # Use base_lrs to force the scheduler to restart at a lower peak (e.g. 0.0008 instead of 0.001)\n",
    "            scheduler.base_lrs = [config[\"lr\"] * cycle_decay for _ in range(len(optimizer.param_groups))]\n",
    "            \n",
    "            scheduler.step(epoch + batch_idx / len(train_loader))\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        total += t_a.size(0)\n",
    "        correct += outputs.argmax(1).eq(t_a).sum().item()\n",
    "\n",
    "    if epoch >= config[\"warmup_epochs\"]:\n",
    "        loss_threshold *= config[\"dynamic_threshold_decay\"]\n",
    "    \n",
    "    epoch_acc = 100.0 * correct / total\n",
    "    keep_rate = (total / initial_batch_count) * 100\n",
    "    \n",
    "    # Debug print for Alpha\n",
    "    print(f\"Keep Rate: {keep_rate:.2f}% | Alpha: {current_soft_alpha:.3f} | Mode: {aug_mode}\")\n",
    "    return running_loss / total, epoch_acc, aug_mode\n",
    "\n",
    "@torch.inference_mode()\n",
    "def val():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, t_a, t_b, lam_t, _ in test_loader:\n",
    "        inputs, targets = inputs.to(device), t_a.to(device)\n",
    "        with torch.autocast(device.type, enabled=enable_half):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        predicted = outputs.argmax(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100.0 * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "@torch.inference_mode()\n",
    "def inference():\n",
    "    model.eval()\n",
    "    \n",
    "    labels = []\n",
    "    \n",
    "    for inputs, _, _, _, _ in test_loader:\n",
    "        inputs = inputs.to(device, non_blocking=True)\n",
    "        with torch.autocast(device.type, enabled=enable_half):\n",
    "            outputs = model(inputs)\n",
    "\n",
    "        predicted = outputs.argmax(1).tolist()\n",
    "        labels.extend(predicted)\n",
    "    \n",
    "    return labels\n",
    "\n",
    "# Initialize WandB\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "run_name = f\"cifar100noisy_{config['model']}_{config['optimizer']}_lr{config['lr']}_bs{config['batch_size']}_{timestamp}\"\n",
    "\n",
    "# wandb.init(\n",
    "#     project=config[\"wandb_project\"],\n",
    "#     name=run_name,\n",
    "#     config=config\n",
    "# )\n",
    "\n",
    "best = 0.0\n",
    "best_epoch = 0\n",
    "\n",
    "# Initialize early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    patience=config[\"early_stop_patience\"],\n",
    "    min_delta=config[\"early_stop_min_delta\"],\n",
    "    mode=config[\"early_stop_mode\"]\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Starting Training - {config['epochs']} epochs\")\n",
    "print(f\"Model: {config['model']} (pretrained on {config['pretrained']})\")\n",
    "print(f\"Optimizer: {config['optimizer'].upper()}, LR: {config['lr']}, Batch Size: {config['batch_size']}\")\n",
    "if config[\"optimizer\"].lower() == \"sgd\":\n",
    "    print(f\"Momentum: {config['momentum']}, Nesterov: {config['nesterov']}\")\n",
    "print(f\"Weight Decay: {config['weight_decay']}, Label Smoothing: {config['label_smoothing']}\")\n",
    "print(f\"Scheduler: {config['scheduler']}\")\n",
    "print(f\"Early Stopping: Enabled (patience={config['early_stop_patience']}, mode={config['early_stop_mode']})\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "with tqdm(range(config[\"epochs\"])) as tbar:\n",
    "    for epoch in tbar:\n",
    "        # 1. Run Train (includes internal per-batch scheduler steps)\n",
    "        train_loss, train_acc, mode = train(epoch)\n",
    "        \n",
    "        # 2. Run Validation\n",
    "        val_loss, val_acc = val()\n",
    "        \n",
    "        # 3. Handle LR logging (step only if NOT per-batch)\n",
    "        if scheduler is not None:\n",
    "            if not config.get(\"scheduler_step_per_batch\"):\n",
    "                scheduler.step()\n",
    "            current_lr = scheduler.get_last_lr()[0]\n",
    "        else:\n",
    "            current_lr = config[\"lr\"]\n",
    "        \n",
    "        # 4. Checkpointing\n",
    "        if val_acc > best:\n",
    "            best = val_acc\n",
    "            best_epoch = epoch\n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_acc': val_acc,\n",
    "                'val_loss': val_loss,\n",
    "            }\n",
    "            if scheduler is not None:\n",
    "                checkpoint['scheduler_state_dict'] = scheduler.state_dict()\n",
    "            torch.save(checkpoint, './best_model.pth')\n",
    "        \n",
    "        # 5. Update Progress Bar & Console\n",
    "        status = f\"Epoch {epoch+1}/{config['epochs']} | Train: {train_acc:.2f}% | Val: {val_acc:.2f}% | Best: {best:.2f}% | LR: {current_lr:.6f}\"\n",
    "        tbar.set_description(status)\n",
    "        print(status)\n",
    "        \n",
    "        # 6. Early stopping check\n",
    "        if early_stopping(val_acc, epoch):\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "            print(f\"Best Val Accuracy: {best:.2f}% at epoch {best_epoch+1}\")\n",
    "            print(f\"{'='*60}\\n\")\n",
    "            break\n",
    "    \n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Training Complete!\")\n",
    "print(f\"Best Val Accuracy: {best:.2f}% at epoch {best_epoch+1}\")\n",
    "print(f\"Loading best model for inference...\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Load best model for inference\n",
    "checkpoint = torch.load('./best_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Best model loaded (Epoch {checkpoint['epoch']+1}, Val Acc: {checkpoint['val_acc']:.2f}%)\\n\")\n",
    "\n",
    "# Generate submission\n",
    "data = {\n",
    "    \"ID\": [],\n",
    "    \"target\": []\n",
    "}\n",
    "\n",
    "print(\"Generating predictions...\")\n",
    "for i, label in enumerate(inference()):\n",
    "    data[\"ID\"].append(i)\n",
    "    data[\"target\"].append(label)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"/kaggle/working/submission.csv\", index=False)\n",
    "\n",
    "# Log final results to WandB\n",
    "# wandb.summary[\"final_best_val_acc\"] = best\n",
    "# wandb.summary[\"best_epoch\"] = best_epoch\n",
    "# wandb.summary[\"total_epochs\"] = config[\"epochs\"]\n",
    "# if scheduler is not None:\n",
    "#     wandb.summary[\"final_lr\"] = scheduler.get_last_lr()[0]\n",
    "# else:\n",
    "#     wandb.summary[\"final_lr\"] = config[\"lr\"]\n",
    "# wandb.summary[\"early_stopped\"] = early_stopping.early_stop\n",
    "# wandb.summary[\"epochs_trained\"] = best_epoch + 1 if early_stopping.early_stop else config[\"epochs\"]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Submission saved to: ./submission.csv\")\n",
    "print(f\"Best model saved to: ./best_model.pth\")\n",
    "print(f\"Best Val Accuracy: {best:.2f}% (Epoch {best_epoch+1})\")\n",
    "if early_stopping.early_stop:\n",
    "    print(f\"Training stopped early (patience reached)\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Finish WandB run\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14551506,
     "sourceId": 123776,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30776,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19940.593449,
   "end_time": "2026-01-10T20:43:02.362072",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-10T15:10:41.768623",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0142fa67110c4e4095517bc997752664": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0339eff810084f799fe9435df488ee8d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "07929f14205348a8b25cf71eef342640": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_61a8a10c61434efc9d2bea1b3ba160ab",
       "placeholder": "​",
       "style": "IPY_MODEL_f71de05a9ad04783b64adf0342a70ce4",
       "value": "model.safetensors: 100%"
      }
     },
     "61a8a10c61434efc9d2bea1b3ba160ab": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7f6d32527cbc4f5aa1ab7b0a82181aee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "80de016dbc19429aa7c75b46cb4803d9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9615bacb57aa4bd590359cc2027b8c9a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0142fa67110c4e4095517bc997752664",
       "placeholder": "​",
       "style": "IPY_MODEL_7f6d32527cbc4f5aa1ab7b0a82181aee",
       "value": " 46.8M/46.8M [00:28&lt;00:00, 1.76MB/s]"
      }
     },
     "ae134576f69040f38df4b96bc701037e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ebab6c15dee440af821cb58d2b6e5682": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ae134576f69040f38df4b96bc701037e",
       "max": 46807446.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0339eff810084f799fe9435df488ee8d",
       "value": 46807446.0
      }
     },
     "f5d47f438b134433a63d54bf7b0c0e12": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_07929f14205348a8b25cf71eef342640",
        "IPY_MODEL_ebab6c15dee440af821cb58d2b6e5682",
        "IPY_MODEL_9615bacb57aa4bd590359cc2027b8c9a"
       ],
       "layout": "IPY_MODEL_80de016dbc19429aa7c75b46cb4803d9"
      }
     },
     "f71de05a9ad04783b64adf0342a70ce4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
